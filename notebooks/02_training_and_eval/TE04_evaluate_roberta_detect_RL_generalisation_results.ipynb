{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the RoBERTa generalisation ability of the DetectRL dataset\n",
    "\n",
    "General info: this notebook does the aggregation of the training results. The training itself is done with the notebook 'T02'\n",
    "\n",
    "0. Setup and data analysis\n",
    "     0. Setup and imports\n",
    "     1. Dataset analysis:\n",
    "        - closer look at DetectRL data folder \"/Benchmark/Benchmark_Data/Tasks\"\n",
    "            --> content of the folder Task1 and Task2 completely identical\n",
    "        - short analysis of the label, domain and attack distribution for the Task1 folder\n",
    "    \n",
    "1. Analyse the generalisation performance of the Regex cleaned data compared to the uncleaned one\n",
    "    - the models are trained on a single llm single domain dataset and evaluated on the other llms in that domain --> the target is to analyse the generalisation performance across multiple LLMs; we especially want to compare the uncleaned llms with the cleaned ones to identify llms and domains, there the cleaning had the highest (positive or negative) impact on the generalisation performance\n",
    "    - Results: \n",
    "        -  Overall only minor differences between the regex cleaned data and the uncleaned one\n",
    "        -  Max. abs differences: change of around 0.06 in f1-score "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6c344a9cfd5a818"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "319f65fe11f6c526"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.0 imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68036cf48b465df"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-06T14:28:30.998137100Z",
     "start_time": "2025-09-06T14:28:15.526470100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 14:28:26.857443: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-06 14:28:26.875544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757168906.897090 1447122 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757168906.903043 1447122 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757168906.919281 1447122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757168906.919300 1447122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757168906.919301 1447122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757168906.919303 1447122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-06 14:28:26.924580: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_DIR = \"../../\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "\n",
    "from src.general_functions_and_patterns_for_detection import (\n",
    "    file_hash,\n",
    "    get_info_based_on_input_path,\n",
    "    load_dataframe_from_json,\n",
    "    TrainRobertaHelper,\n",
    "    RESULT_DIR, CLEANED_FILES_DIR, ORIGINAL_DATA_DIR, \n",
    "    DETECT_RL_DIR, TASK_DIR,\n",
    "    LLMs, DOMAINS, COLUMNS_DIRECTLY_LLM_GENERATED_DETECT_RL as LLM_PROMPTS,\n",
    ")\n",
    "\n",
    "prepare_df_for_roberta_training = TrainRobertaHelper.prepare_df_for_roberta_training\n",
    "\n",
    "sys.path.append(os.path.join(DETECT_RL_DIR, \"Detectors\"))\n",
    "import DetectRL.Detectors.train_roberta as train_roberta\n",
    "\n",
    "DEBUG = True\n",
    "DRY_RUN = False\n",
    "ALL_DATA = True\n",
    "SEED = 2023\n",
    "logging.basicConfig(level=logging.WARNING, format=\"%(asctime)s %(levelname)s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "task1_path = f\"{TASK_DIR}/Task1/\"\n",
    "task2_path = f\"{TASK_DIR}/Task2/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-06T14:28:31.053252900Z",
     "start_time": "2025-09-06T14:28:31.000140400Z"
    }
   },
   "id": "a6956259b0419b39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.1 Take a look at the different paths"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be4be03f7d4b7b02"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal rows: 349165\n",
      "Unequal rows: 0\n"
     ]
    }
   ],
   "source": [
    "task1_dir = task1_path\n",
    "task2_dir = task2_path\n",
    "\n",
    "unequal_rows_df = pd.DataFrame()\n",
    "equal_count = 0\n",
    "unequal_count = 0\n",
    "\n",
    "for filename in os.listdir(task2_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        path2 = os.path.join(task2_dir, filename)\n",
    "        path1 = os.path.join(task1_dir, filename)\n",
    "\n",
    "        if not os.path.exists(path1):\n",
    "            print(f\"File {filename} not found in Task1. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        hash1 = file_hash(path1)\n",
    "        hash2 = file_hash(path2)\n",
    "\n",
    "        if hash1 == hash2:\n",
    "            df = pd.read_json(path2, encoding=\"utf-8\")\n",
    "            equal_count += len(df)\n",
    "        else:\n",
    "            print(path1, \"and\", path2, \"are not the same by hash, checking for the rows\")\n",
    "            df1 = pd.read_json(path1)\n",
    "            df2 = pd.read_json(path2)\n",
    "\n",
    "            # Align columns to prevent misalignment\n",
    "            common_columns = df1.columns.intersection(df2.columns)\n",
    "            df1 = df1[common_columns]\n",
    "            df2 = df2[common_columns]\n",
    "\n",
    "            matches = df1.equals(df2)\n",
    "            if matches:\n",
    "                equal_count += len(df1)\n",
    "            else:\n",
    "                # Compare row-wise\n",
    "                comparison = df1.eq(df2)\n",
    "                row_equality = comparison.all(axis=1)\n",
    "\n",
    "                equal_rows = df2[row_equality]\n",
    "                unequal_rows = df2[~row_equality]\n",
    "\n",
    "                equal_count += len(equal_rows)\n",
    "                unequal_count += len(unequal_rows)\n",
    "\n",
    "                unequal_rows_df = pd.concat([unequal_rows_df, unequal_rows], ignore_index=True)\n",
    "\n",
    "print(f\"Equal rows: {equal_count}\")\n",
    "print(f\"Unequal rows: {unequal_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-06T14:28:59.902889100Z",
     "start_time": "2025-09-06T14:28:40.628846800Z"
    }
   },
   "id": "23d7b4f1db702a4c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label', 'data_type', 'llm_type'], dtype='object') Index(['text', 'label', 'data_type', 'llm_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for llm in LLMs:\n",
    "    other_LLMs = list(set(LLMs) - {llm})\n",
    "\n",
    "    # Train and test for the current LLM\n",
    "    train_df = load_dataframe_from_json(os.path.join(task1_path, f\"multi_llms_{llm}_train.json\"))\n",
    "    test_df = load_dataframe_from_json(os.path.join(task1_path, f\"multi_llms_{llm}_test.json\"))\n",
    "    \n",
    "    if llm == \"ChatGPT\":\n",
    "        break\n",
    "        \n",
    "print(train_df.columns, test_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-06T14:29:03.730391800Z",
     "start_time": "2025-09-06T14:29:03.142423500Z"
    }
   },
   "id": "d5a3a36a14b4c32c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "label\nllm      24187\nhuman     1800\nName: count, dtype: int64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"label\"]].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-20T12:45:25.556165500Z",
     "start_time": "2025-07-20T12:45:25.524502300Z"
    }
   },
   "id": "2b9bb8249d3c7dde"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "data_type\nabstract    450\ndocument    450\nstory       450\ncontent     450\nName: count, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df_1 = train_df[train_df[\"label\"]==\"human\"]\n",
    "human_df_1[\"data_type\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-20T12:45:25.638491300Z",
     "start_time": "2025-07-20T12:45:25.543507600Z"
    }
   },
   "id": "c769b7a4c640f365"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "data_type                        label\nadversarial_character_llm        llm      2688\nadversarial_word_llm             llm      2688\nadversarial_character_word_llm   llm      2688\nparaphrase_back_translation_llm  llm      2688\ndirect_prompt                    llm      2688\nprompt_few_shot                  llm      2688\nparaphrase_polish_llm            llm      2688\nprompt_SICO                      llm      2688\nparaphrase_dipper_llm            llm      2683\ncontent                          human     450\nabstract                         human     450\ndocument                         human     450\nstory                            human     450\nName: count, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"data_type\", \"label\"]].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-20T12:45:25.667894900Z",
     "start_time": "2025-07-20T12:45:25.550165500Z"
    }
   },
   "id": "6863087e61485685"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "data_type                        label  llm_type\nabstract                         human  ChatGPT     250\ncontent                          human  ChatGPT     250\ndocument                         human  ChatGPT     250\nstory                            human  ChatGPT     250\nadversarial_character_llm        llm    ChatGPT     112\nadversarial_word_llm             llm    ChatGPT     112\nadversarial_character_word_llm   llm    ChatGPT     112\nparaphrase_back_translation_llm  llm    ChatGPT     112\ndirect_prompt                    llm    ChatGPT     112\nparaphrase_dipper_llm            llm    ChatGPT     112\nparaphrase_polish_llm            llm    ChatGPT     112\nprompt_SICO                      llm    ChatGPT     112\nprompt_few_shot                  llm    ChatGPT     112\nName: count, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[\"data_type\", \"label\", \"llm_type\"]].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-20T12:45:25.687139400Z",
     "start_time": "2025-07-20T12:45:25.565108800Z"
    }
   },
   "id": "6dc7c782b80b3eb7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "data_type                        label  llm_type\nadversarial_character_llm        llm    ChatGPT     2688\nadversarial_word_llm             llm    ChatGPT     2688\nadversarial_character_word_llm   llm    ChatGPT     2688\nparaphrase_back_translation_llm  llm    ChatGPT     2688\ndirect_prompt                    llm    ChatGPT     2688\nprompt_few_shot                  llm    ChatGPT     2688\nparaphrase_polish_llm            llm    ChatGPT     2688\nprompt_SICO                      llm    ChatGPT     2688\nparaphrase_dipper_llm            llm    ChatGPT     2683\ncontent                          human  ChatGPT      450\nabstract                         human  ChatGPT      450\ndocument                         human  ChatGPT      450\nstory                            human  ChatGPT      450\nName: count, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for llm in LLMs:\n",
    "    other_LLMs = list(set(LLMs) - {llm})\n",
    "\n",
    "    # Train and test for the current LLM\n",
    "    train_df = load_dataframe_from_json(os.path.join(task2_path, f\"multi_llms_{llm}_train.json\"))\n",
    "    test_df = load_dataframe_from_json(os.path.join(task2_path, f\"multi_llms_{llm}_test.json\"))\n",
    "    \n",
    "    if llm == \"ChatGPT\":\n",
    "        break\n",
    "\n",
    "train_df[[\"data_type\", \"label\", \"llm_type\"]].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-20T12:45:26.083165Z",
     "start_time": "2025-07-20T12:45:25.604425600Z"
    }
   },
   "id": "63849d9fcd10612c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "llm      1008\n",
      "human    1000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "data_type                        label  llm_type\nabstract                         human  ChatGPT     250\ncontent                          human  ChatGPT     250\ndocument                         human  ChatGPT     250\nstory                            human  ChatGPT     250\nadversarial_character_llm        llm    ChatGPT     112\nadversarial_word_llm             llm    ChatGPT     112\nadversarial_character_word_llm   llm    ChatGPT     112\nparaphrase_back_translation_llm  llm    ChatGPT     112\ndirect_prompt                    llm    ChatGPT     112\nparaphrase_dipper_llm            llm    ChatGPT     112\nparaphrase_polish_llm            llm    ChatGPT     112\nprompt_SICO                      llm    ChatGPT     112\nprompt_few_shot                  llm    ChatGPT     112\nName: count, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_df[\"label\"].value_counts())\n",
    "test_df[[\"data_type\", \"label\", \"llm_type\"]].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-20T12:45:26.113290600Z",
     "start_time": "2025-07-20T12:45:26.084107100Z"
    }
   },
   "id": "e02c4a569db1e266"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "946ab23d7d3cf9fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.0 General functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b84d075ec732f965"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Aggregate Training Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc12d6ead067b07e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT xsum paraphrase_polish_human\n"
     ]
    }
   ],
   "source": [
    "data_paths = [CLEANED_FILES_DIR, ORIGINAL_DATA_DIR]\n",
    "# DOMAINS = [\"writing_prompt\"]\n",
    "result_list = []\n",
    "count_runs_done = 0\n",
    "count_runs_missing = 0\n",
    "\n",
    "for h, _domain in enumerate(DOMAINS):\n",
    "    for j, _llm in enumerate(LLMs):\n",
    "        for k, prompt in enumerate(LLM_PROMPTS):            \n",
    "            training_df_original = load_dataframe_from_json(f\"{ORIGINAL_DATA_DIR}{_domain}_2800.json\")\n",
    "            training_df_cleaned = pd.read_parquet(f\"{CLEANED_FILES_DIR}{_domain}_2800_cleaned_all_v2.parquet\")\n",
    "            _, prompt_key, human_key = get_info_based_on_input_path(_domain)\n",
    "            training_df_original = prepare_df_for_roberta_training(training_df_original, column_to_be_used_for_text=prompt,\n",
    "                                                          column_to_be_used_for_human=human_key, column_title=prompt_key)\n",
    "            training_df_cleaned = prepare_df_for_roberta_training(training_df_cleaned, column_to_be_used_for_text=prompt,\n",
    "                                                          column_to_be_used_for_human=human_key, column_title=prompt_key)\n",
    "            training_df_original = train_roberta.hash_dataframe_as_parquet(training_df_original[training_df_original[\"llm_type\"]==_llm])\n",
    "            training_df_cleaned = train_roberta.hash_dataframe_as_parquet(training_df_cleaned[training_df_cleaned[\"llm_type\"]==_llm])\n",
    "            \n",
    "            if training_df_cleaned == training_df_original:\n",
    "                print(_llm, _domain, prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-06T14:46:21.274639600Z",
     "start_time": "2025-09-06T14:45:05.405551200Z"
    }
   },
   "id": "3a906c169de567c3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "RESULT_DIR = \"/mnt/hdd-baracuda/pdingfelder/Training_Results\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-06T14:57:52.364075700Z",
     "start_time": "2025-09-06T14:57:52.326510300Z"
    }
   },
   "id": "fff50df215271575"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:20<00:00, 20.01s/it]\n"
     ]
    }
   ],
   "source": [
    "data_paths = [CLEANED_FILES_DIR, ORIGINAL_DATA_DIR]\n",
    "# DOMAINS = [\"writing_prompt\"]\n",
    "result_list = []\n",
    "count_runs_done = 0\n",
    "count_runs_missing = 0\n",
    "\n",
    "for h, _domain in enumerate(tqdm(DOMAINS)):\n",
    "    for j, _llm in enumerate(LLMs):\n",
    "        for k, prompt in enumerate(LLM_PROMPTS):\n",
    "            for i, _train_path in enumerate(data_paths):\n",
    "                result = {}\n",
    "                if _train_path.startswith(ORIGINAL_DATA_DIR):\n",
    "                    training_df = load_dataframe_from_json(f\"{ORIGINAL_DATA_DIR}{_domain}_2800.json\")\n",
    "                    # print(\"original\")\n",
    "                else:\n",
    "                    training_df = pd.read_parquet(f\"{CLEANED_FILES_DIR}{_domain}_2800_cleaned_all_v2.parquet\")\n",
    "                    # print(\"cleaned\")\n",
    "                _, prompt_key, human_key = get_info_based_on_input_path(_domain)\n",
    "                training_df = prepare_df_for_roberta_training(training_df, column_to_be_used_for_text=prompt,\n",
    "                                                              column_to_be_used_for_human=human_key, column_title=prompt_key)\n",
    "                df_claude = training_df[training_df[\"llm_type\"]==_llm]\n",
    "                other_llms = LLMs.copy()\n",
    "                other_llms.remove(_llm)\n",
    "                df_llama, df_palm, df_chatgpt = [training_df[training_df[\"llm_type\"]==_llm].dropna(subset=[\"label\", \"text\"]) for _llm in other_llms]\n",
    "                # print(df_claude.head())\n",
    "                \n",
    "                train_df, test_df = train_test_split(df_claude, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "                # print(train_df.shape, test_df.shape, len(df_llama), len(df_claude), len(df_chatgpt),\n",
    "                #  train_df.columns)\n",
    "                \n",
    "                save_model_path = f\"{RESULT_DIR}/{_llm}_{prompt}_test\"\n",
    "                dict_temp = {_llm: test_df, other_llms[0]: df_llama, other_llms[1]: df_palm, other_llms[2]: df_chatgpt}.items()\n",
    "                for key, df in dict_temp:\n",
    "                    df_hash = train_roberta.hash_dataframe_as_parquet(df)\n",
    "                    result_path = f\"{save_model_path}/{df_hash}.roberta-base_result.json\"\n",
    "                    if os.path.exists(result_path):\n",
    "                        with open(result_path) as fp:\n",
    "                            result = json.load(fp)\n",
    "                        fp.close()\n",
    "                        result[\"training_llm\"] = _llm\n",
    "                        result[\"test_llm\"] = key\n",
    "                        result[\"hash_df\"] = df_hash\n",
    "                        result[\"domain\"] = _domain\n",
    "                        result[\"cleaned\"] = _train_path == CLEANED_FILES_DIR\n",
    "                        result[\"llm_prompt\"] = prompt\n",
    "                        result_list.append(result)\n",
    "                        count_runs_done += 1\n",
    "                    else:\n",
    "                        count_runs_missing += 1\n",
    "print(count_runs_done, count_runs_missing)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-06T14:59:17.138328700Z",
     "start_time": "2025-09-06T14:57:57.064946300Z"
    }
   },
   "id": "e6887901996acf16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(result_list)\n",
    "df_results.sort_values([\"roc_auc\"], inplace=True)\n",
    "df_results.drop(columns=[\"hash_df\", \"optimal_threshold\", \"conf_matrix\"]).reset_index(drop=True).head(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fad3c7718fe36a75"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Here is a 22 sentence story in a more human writing style based on the prompt:It was a quiet autumn evening when Death realized something was stirring within her cosmic being. As her spectral hands wandered over her robed figure, she felt an unexpected warmth in her core.  Puzzled, she retired to her gloomy realm for deliberations. Through the long night, mysterious flutters arose within the void of her soul. Come dawn, Death ventured to the lands of the living to seek counsel. Among the bereaved arranging funerals scheduled for dreary weeks ahead, Life spotted Death's troubled gaze.\"What ails you my old friend?\" inquired Life with sincere concern. Death grasped Life's vibrant hands and confided her strange discovery through tears of netherworld mist.  Stunned into rare silence, Life processed this unthinkable notion. \"But how can it be?\" wondered Life aloud. Death had no answers to the question echoing in her hollow bones.Together they sought the wisdom of Time in his endless halls. Upon hearing their troubling news, even the ancient clockmaker was left perplexed.\"This is indeed an enigma beyond my vast memories\" muttered Time while stroking his age-old beard.As the three powerful beings debated the unlikely circumstance, a thought formed in Life's fertile mind.\"Perhaps it is a sign that we must bring more balance to the great cycle.\" suggested Life with a bloom of color returning to Death's ashen cheeks.In the coming moons, Death's figure began to change with new life stirring within. Though disquieting to mortals, a delicate tenderness emerged in Death's demeanor.  As her time drew near, Life comforted Death with promises of nurturing their child with compassion for all living souls.On a misty Samhain eve amid colorful leaves floating downstream, Death was overtaken by pangs beyond any reaper's scythe.Through the night hours within her ominous halls, Death labored with Life's gentle aid.\n",
      "\n",
      " As an AI language model, I am unable to engage with content that may violate my usage guidelines. To learn more, visit https://poe.com/usage_guidelines. As an AI language model, I am unable to engage with content that may violate my usage guidelines. To learn more, visit https://poe.com/usage_guidelines.\n",
      "\n",
      " Here is a 25 sentence story in a more human conversational style based on the prompt:Man, I still can't believe 25% of people suddenly got superpowers last month. Nobody knows what caused that massive flashed in the sky or how some folks changed after. All I know is my life has been flipped upside down since. Now everywhere I go there's some dude floating by or zapping things with their eyes. At first it was kinda cool to see but now it's just annoying. Like bro, you don't need to blast your laser vision every five seconds to show off. Work has been a struggle too. My boss Jerry got super strength so he keeps making me do all the heavy lifting. Like yeah, I get it dude you can bench press a truck now but I'm still doing most the real work around here. Even going to the store is a pain. There was a big fight in the parking lot last week between some speedster and pyro. Burnt half the cars before the cops even showed up. Whatever, I just wanna get my groceries without worrying I'll get smoked by a flying fist.  Don't even get me started on the girls either. All the cute ones at the bar now only give half a shit about the normies like me. They're all chasing some dude who can teleport or read minds or something. Like yeah, okay, reading my thoughts does sound pretty cool but I still have feelings too ya know! I'm tellin' ya, it's like the whole world passed me by overnight. And for what? I'm just the same guy trying to get through each day. I don't need no freaky powers messing up my already weird life, whatever the hell that even means anymore. I just hope things calm down before someone who can shatter bones by yelling eventually yells at the wrong guy. Like maybe me.\n",
      "\n",
      " Here is a 21 sentence story in human style writing based on the prompt \"I miss you\":I miss you dude, it's just not the same without you around. We've been friends forever it feels like, since we were kids playing ball in the street after school. Remember all the trouble we used to get into? Man, the memories bring a smile to my face but also tears to my eyes. I was hoping to hang this weekend, it's been too long. Like, I know you've been busy with the new job and the move across town but come on! You gotta make time for your best friend, yeah? I just feel like we're driftin' apart bit by bit even though I don't want that. Gotta admit, it's lonely as hell without my partner in crime to call up whenever. I keep thinking back to all the good times we had growin' up, sneakin' out at night, getting into adventures... Simpler times it seems now. What do you say, can you come over Saturday? We'll order a pizza, crack open a few beers and shoot the shit like old times. Maybe even convince Sarah to come by, you know she still asks about you sometimes. I was thinking we could also hit the game Sunday if you're not too hungover! Text me back, man, let me know what your plan is. It's been too long since we just hung out, I miss my friend... I miss the laughs we shared. Don't be a stranger, okay? Let me know! I'm counting on seeing your face this weekend, it'll be good to catch up.\n",
      "\n",
      " Here is a 12 sentence story in a more human writing style based on the prompt:As the expectant mother's due date grew nearer, a dark omen loomed over the once joyous family. None dared speak of the rumor that had haunted their village for generations - that with new life would come loss. When the baby arrived, screams of pain were soon replaced with coos of affection, but all knew what was yet to come. In the dead of night, the elder grandfather awoke with a start, feeling an invisible force pulling at his soul. As he lifted creaking bones from the bed for the last time, he watched over his sleeping family with eyes brimming with sad farewells. Stealing into the forest under the light of the moon, his feet guided him deeper into the ancient trees than ever before. A mighty roar split the silent night air, and through tear-filled eyes the man glimpsed a monstrous shadow emerging from the mists. With strength borne of protecting his kin, he faced the approaching beast without fear. As claws the size of swords descended, his final thought was of the innocent child who would never know his face. When dawn broke through the foliage, all that remained was a scene of scattered feathers and shards of bloodstained shadow. Back in the village, wails of sorrow signaled the mysterious disappearance, and with heavy hearts the family braced for the legacy to continue with the next generation.\n",
      "\n",
      " Here is a 40 sentence story in attempted human style writing:The villagers held their breath as they peered through the thick trees at the Dragon's castle. For years they lived in fear of the beasts that ruled the land. But now, with so few villagers left, they knew they had to take a stand or face the end. Bartolomew gripped his rusted sword, anxious about what was to come. \"This may be suicide,\" he whispered to the others. But they had no other choice. They watched and waited for night to fall, hoping the dark cover might help them sneak in unnoticed.  As the sun sank low on the horizon, the group gathered their courage and began stealthily moving towards the stone walls. Lucinda's heart pounded in her chest. She wished for anything but what they had planned. But the faces of her children, lost to the Dragon's flames, kept her pushing forward. Keeping to the shadows, they crept along the edge, searching for an opening. Bartolomew spotted a loose brick and, with all his strength, pulled it free. Just big enough to slip through one by one. They held their breath and listened, but heard nothing within. Tiptoeing further into the dark corridors, they prayed no guards would come upon them.Down winding stairs and twisting halls they went 'til they spotted a faint glow ahead. Pressing themselves to the cold stones, they peered into a massive chamber, the lair of the King himself. There, resting upon a pile of glittering treasures, was the mighty beast. Far larger than any dragon they'd ever seen. But they were here now, this was their chance. With no other choice left, they readied for the final stand.\n",
      "\n",
      " Here is a 36 sentence story based on the prompt:I found the tiny spider scuttling across my windowsill one afternoon and thought it might enjoy a new hobby. \"Little friend,\" I said, \"would you like to learn how to knit?\" The spider tilted its head, curious about this tall creature before it. I gathered some thin yarn and knitting needles small enough for its spindly legs. \"Watch closely now,\" I instructed, looping the yarn around the needle with steady movements. However, the spider seemed more interested in crawling up my arm than paying attention to the lesson. \"No no, focus here,\" I redirected, placing it back on the sill. Again it climbed, this time making its way to my head where it started to weave a web in my hair. \"Ahh, not there!\" I cried, brushing it away in a frenzied dance. This was proving far more complicated than I expected. Over the following days, I fashioned tiny knitting implements and left scraps of fiber for the spider to investigate. At first it showed no understanding of the craft, instead consuming the yarn as food. Still I persisted, miming the movements each afternoon. Gradually, it began to mimic my looping motions, coordinating eight legs into a slow, shaky pattern. Weeks later, the first knotted strand emerged, and I congratulated my student with an enthusiastic \"Well done!\" Proud of its handiwork, the spider scurried off into the evening, the beginnings of a web slung over its spindles. Though progress was gradual, it seemed our lesson was finally taking shape.\n",
      "\n",
      " Here is an 18 sentence story in a more human style:1) Gordon Ramsay stared at Bear Grylls with his usual scowl.  2) \"Drinking your own pee? Really mate?\" 3) Bear just grinned and winked. \"It's all part of the experience Gordon!\"4) Gordon grimaced at the thought. \"Can't we just roast some rabbits over the fire instead?\"5) \"Now that's more my speed,\" agreed Bear. \"But we're here for an adventure!\"6) So Gordon reluctantly followed Bear into the forest, mumbling curses under his breath.7) They stumbled upon a stream and Bear declared they should catch some fish.  8) \"With what?\" asked Gordon skeptically. \"Our charming personalities?\"9) Bear just laughed. \"Leave it to me, you squeamish chef.\"  10) Moments later Bear returned with two fish, much to Gordon's relief.11) \"Alright, you hooked 'em, now how about I cook 'em?\" Gordon offered eagerly.12) Soon they were enjoying flaky grilled fish by the river. 13) \"Not bad Ramsey!\" Bear congratulated. \"Maybe you do belong out here after all.\"14) Gordon just shot him a look. \"Don't get used to it, this is a one time thing.\"15) Just then they heard a strange noise in the bushes. Bear leapt up excitedly.16) \"What now?\" sighed Gordon as a giant grizzly emerged with a low growl. 17) \"Poof!\" cried Bear, disappearing in a cloud of smoke.  18) \"Thanks for nothing you outdoorsy wanker,\" muttered Gordon, backing away slowly from the angry bear.\n",
      "\n",
      " Here is a 25 sentence story in a more human conversational style based on the writing prompt:Dave was bored out of his mind, staring at a blank word document for hours. \"I gotta write something to pass the time,\" he thought. But coming up with an idea was harder than he expected. Then it hit him - he'd write a story about a writer writing a story! That should be easy enough. He started typing about a guy named John, sitting at his desk trying to think of what to write. John wasn't having any luck until he thought, \"What if I wrote about someone else writing?\" So in his story, the character Bill was struggling for ideas too. But Bill decided to pen a tale of a writer's plight. He described his main character Steve booting up his laptop, already drained before putting words on the page.Steve thought being creative for a living would be awesome but most days it felt like a drag. He scrolled aimlessly online hoping for inspiration to strike. Nothing was coming to mind until a lightbulb flashed. Steve would write about a writer at wit's end! And so in his story, Tom paced around empty-headed.Tom was about to call it quits when a thought popped in his head. What if he crafted a story about a author stuck for thoughts? Now he just needed a name.\"Bob,\" Tom said aloud as he sat down to type. And that's how Bob came to be, stuck behind his desk just like Tom, John, Bill, and Steve before him. Bob stared at the blank screen thinking this was the dumbest idea ever. \"Four guys writing stories about each other writing stories?\" But it was too late now, the tale was unfolding. So Bob described his predicament, hoping whoever read it found it amusing at least.Little did Bob know, Dave was grinning as the story took shape on his screen. \"Crazy how shit like that happens sometimes,\" he chuckled to himself.Dave had to admire the ridiculousness of it all - a man writing a story about a man writing a story about a man writing a story about a man writing a story.\n",
      "\n",
      " Here is a 30 sentence story in a more human conversational style in response to the prompt:So get this, yesterday was just such a weird day, like really weird. I woke up and something just felt off, ya know? Everything just seemed kinda gray if that makes any sense. Anyway, I went about my morning like normal, had some coffee and tried to wake up but nothing was working. Even my favorite show didn't crack a smile. Figured a change of scenery may help so I went for a long walk in the park. On my way out I tripped over nothing and fell flat on my face. I mean how clumsy can you get, right? But even that didn't cheer me up which is really strange cause I'm usually laughing at myself. The park was dead, like not a soul in sight. Started thinking maybe there was a zombie outbreak or aliens invaded while I was sleeping or something. Weirded me out big time. I sat by the lake for awhile just watching the water, don't know what I was hoping to see but nothing was there. Felt like the loneliest person alive. Making my way home I started coming up with all these ridiculous ideas to liven my mood. Thought maybe if I staged a fake kidnapping or robbery it may give me a good scare. Figured I could call the cops pretending to be a hostage then when they busted in I'd jump out and yell \"Surprise!\" Bet that would get their hearts pumping, ha. Or maybe I could hide in my own house and lunge out at myself when I walked through the door. Boy, that'll be a hoot. I was laughing just thinking about their faces. Finally I came up with the best plan yet. I'd write a super funny suicide note but in a totally joking and sarcastic way so when they found me they'd laugh and know it was all just a prank. What a great way to go out, with everyone having a good laugh, right? Guess the joke's on me now, huh. I really didn't think anyone would actually find me, just wanted to add some humor to an otherwise dark day. Well, that's about it folks.\n",
      "\n",
      " Here's an 18 sentence story in a more human conversational style to match the prompt:Man, I was so pissed after that party last night. I saw her dancing with that dude Ryan, getting all cozy like they were together or something. It bugged me, I don't know why but it really bugged me. I've known Sarah for forever, we grew up together but I never made a move or anything. Anyway, I had to get out of there so I just started walking, trying to clear my head. But I just kept thinking about them dancing and laughing together. Next thing I know I'm at the pier, looking out at the water. That's when I hear someone walking up behind me. \"Damn Ryan, leave me alone\" I said, not even turning around. But then she said \"It's not Ryan, it's me.\" I spun around and there was Sarah standing there. \"What are you doing out here?\" she asked. I didn't know what to say so I just shrugged. We stood there in silence for a few minutes, both looking out at the water. Then she said \"Why did you leave so early?\" I took a deep breath. \"I don't know, seeing you with him just bugged me I guess.\" She looked confused. I thought what the hell, might as well tell her. \"I wanted it to be me dancing with you, Sarah. God damn, I really did.\" The expression on her face, I'll never forget it. She just smiled and said \"Well why didn't you ever ask me to dance before?\" And then, I swear to god, she took my hand in hers and we walked back to the party. Together.\n",
      "\n",
      " Here is a 28 sentence story in a more human literary style based on the prompt:The fog melted away like cotton candy in rain to reveal clouds of the softest substance. I stared into the billowing abyss, feeling its gentle abyss stare back with warmth. Beneath my feet, the clouds pulsated with a heartbeat unlike anything I'd felt before. A faint static buzzed just below the surface, like swarm of fireflies dancing to a tune only they could hear. Voices materialized out of the whiteness, melodic and sweet as chiming bells. \"Welcome,\" they sang, \"stay and bask in our glow.\" I closed my eyes, letting the blinding white wash over my skin in soothing waves. When I opened them again, seraphim floated nearby, rippling wings shimmering with ethereal iridescence. One smiled, teeth like perfectly crafted pearls. \"Come,\" it beckoned me upwards with slender fingers. Higher we rose until below stretched perfect emerald pastures dotted with souls at peaceful play. Some lounged amid floral tapestries more vibrant than any garden on Earth, and others strummed harps sweeter than starlight. The static swelled, a heavenly choir joining its chorus as new arrivals emerged from the fog.  We drifted over friends and family, their empty earthly shells shed as radiant spirits. Joy swelled within my newly eternal form at being reunited, our fingers tapping out a rhythm across the clouds. Laughter spilled from our lips, pure mirth lacking pain or sorrow. As the sun set in a rainbow sky, colors rippled like ribbons to dance the night in. Sleep came softly, like falling into the arms of God upon the filthy cushions of a train.Dreams wove memories of life into fantastical tapestries, where loss faded and loved ones lingered. At dawn, dew glistened on clouds fresher than mountain air. Birdsong heralded a new day of infinite wonder and companions in this eternal realm apart from sorrow. A perfect peace sat within my soul, content to bask in divine delight through sweet eternity.\n",
      "\n",
      " Here is a 17 sentence story in a more human-like style based on the prompt:Geopolitical tensions had been rising for years between the two superpowers as their struggle for global influence intensified. Spy satellites detected mysterious activities at alleged nuclear weapons sites as politicians on both sides made increasingly brazen claims and counterclaims. Disinformation spread rapidly online, inflaming nationalist passions and undermining diplomacy. At an emergency UN Security Council meeting, the ambassadors trading heated accusations and presenting contradictory intelligence reports, with the arbitrating powers unable to broker a consensus. Behind closed doors, delegates knew their countries had ulterior geopolitical motives that risked escalating the crisis beyond control. As a last resort, a group of independent scholars proposed a hypothetical framework for nuclear disarmament that could gradually reestablish mutual trust. However, their well-intentioned musings attracted scathing criticism from hawkish factions demanding a show of strength. Without warning, bombings of strategic military bases began along the contested borderlands. Despite desperate calls for restraint, advanced weapons systems already on high alert launched within minutes, seeking to preempt further attacks. Once the first nuclear device detonated with terrifying ferocity, decades of precarious stability instantly collapsed.  Panic ripped across the continents as seismic alerts of massive explosions were followed by clouds of blinding fire reaching into the sky. Governments issued conflicting reports about the scale of strikes between machine-translated messages of fury and revenge. In the attack's aftermath, those living near the blast zones were afflicted with acute radiation sickness. International organizations raced to repatriate refugees flooding across borders with aid convoys despite the hazardous environment.\n",
      "\n",
      " Here is a 31 sentence story based on the prompt:The time traveler's quantum suit activated, transporting them back to a dusty road in ancient Rome. A young Julius Caesar stared in awe from his family's vineyard. \"One day, your armies will conquer Gaul and you will become dictator of Rome.\" Flashing forward, Caesar struggled to breathe in the Senate building. \"Your name will forever be synonymous with leadership and your calendar still used today.\" Emerging in 18th century Scotland, a curious James Watt tinkered in his workshop. \"Your improvements to the steam engine will fuel the Industrial Revolution.\" On his deathbed, the time traveler said \"Your name lives on in every watt of energy produced.\"Transporting to the American Southwest, a young Sacagawea helped her fellow Shoshone tribe members. \"One day, your skills as a guide and translator will help Lewis and Clark map the new nation.\" On the Oregon Trail, Sacagawea smiled weakly hearing \"The story of your courage will inspire generations of Native Americans.\"  In the Swiss Alps, a young Albert Einstein puzzled over school lessons. \"Your theory of relativity will revolutionize physics and earn you a Nobel Prize.\" From his hospital bed, Einstein grinned hearing \"You will be remembered as one of the smartest humans who ever lived.\"And so the time traveler continued visiting historical figures in their childhood and final moments, sharing glimpses of their impact while maintaining the integrity of the timeline. Though lives were temporary, legacies could echo through the ages if one remained determined to better the world, no matter how humble their beginnings.\n",
      "\n",
      " Here is a 20 sentence story in a more human conversational style based on the prompt:Man, I can't believe we actually pulled it off. When the villain said he was going to destroy the city unless we solved some crazy math problem, I thought we were screwed for sure. But then my buddy Jane was like \"hey, I think I know an obscure concept that just might work.\" The rest of us were like \"uh huh, sure lady.\" But she laid it out for us anyway. Turns out there was this wacky topological concept called \"braneworlds\" or something nuts like that. Jane said if we could model the city and the villain's doomsday device in higher dimensions, we might be able to alter things without them noticing. I said \"You've lost it, this will never work.\" But we were desperate so we let her take a crack at it. To make a long story short, she busted out the chalk and started drawing figures all over the sidewalk. The rest of us stood around scratching our heads like \"WTF is this son of a bitch doing?\" But after a couple hours she stepped back with a big \"A-ha!\" and said it was done. When the time came, the villain pushed the button on his device but nothing happened. He was like \"what black magic is this!?\" and we just smiled. Turns out Jane's math voodoo had stabilized the higher dimensions so his machine couldn't function. City saved! I'll never doubt that girl's big brain ever again.\n",
      "\n",
      " Here is a 17 sentence story in attempted human style writing:Well if it isn't St. Peter himself, wasn't expecting to see you so soon but I suppose everyone's time comes eventually. Looks like my coding days aren't over after all, huh? God says he'll let me into Heaven if I help him debug the ol' human system, guess I don't have much choice but to accept. So he gives me the rundown on all the bugs and issues he's been trying to work out. Knees and backs seem to cause a lot of crashes, definitely need some improvements there. And will someone please patch that appendix error, so many pointless crashes caused by that obsolete piece of hardware. The brain is beautifully complex but boy could it use some optimization, maybe add some more RAM too while we're in there. Mental health issues like depression and anxiety really bring the whole experience down, gotta reinforce that positivity subroutine. Oh and that whole aging thing, maybe we roll it back or find a way to halt depreciation after a certain point. I get to work fixing what I can and God seems pretty pleased with the results so far. We throw a public beta for the next major release, version 2.0 of the human system. Early feedback looks very positive, no reports of blown knees or sliced appendices since the update. Minds seem clearer, happiest I've ever seen folks. We may have solved depression and increased baseline happiness levels, good work if I do say so myself. Bodies holding up better too, definitely fewer trips to mechanic overall. Looks like this upgrade is going to really improve the user experience.Guess I earned my place in Heaven after all. Not a bad way to spend eternity if you ask me, always room for more improvements too. The work is never done but it's sure fun to play God sometimes, or should I say work for God! The old man definitely knows how to keep me busy.\n",
      "\n",
      " Here is a 41 sentence story in response to the prompt:The wise old sage asked, \"Where are you from?\" The young girl looked up from her work in the garden and smiled at the stranger. \"Same place as you,\" she replied cryptically.Intrigued, the sage sat on a nearby log and watched the girl tend to the colorful array of florabefore her. \"Do elaborate child, I'm curious as to what lands we both call home.\"She brushed the dirt from her hands and gazed towards the surrounding woodland in reflection. \"This valley and forest is the only home I've ever known.\" \"An interesting answer yet no place at all,\" the sage pondered aloud. \"Surely you must come from a village or town somewhere beyond these trees.\"The girl thought for a moment before responding. \"All places are connected whether near or far, our lives intertwined like the roots beneath the soil.\" Unconvinced, the man pressed further. \"While truth resides in your words, one is always born of somewhere. Now I ask again kindly, what village do you and your people hail from?\"She stood and began walking amongst the flower patches, stopping to tend to those in need. \"My people are but shards of what once was, our homeland now just memories carried by wind.\" The old man listened intently, intrigued by her vague responses. \"What calamity could have befallen your folk to scatter them so?\"Looking to the mountains in the distance, her eyes grew misty and sad. \"A darkness came without warning, twisting minds and hearts until all that remained was fear and violence.\" The sage nodded solemnly. \"I see now the tragedy that forced your exodus. Know that you'll always find shelter here despite your unknown roots.\"She smiled at the kindness of a stranger. \"And you'll find we all spring from the same earth, regardless of the path that brought us to this place we now call home.\"\n",
      "\n",
      " Here is a 27 sentence story in a more human writing style based on the prompt:I remember dyin' clear as day, then wakin' up in this tiny body. Didn't take long to figure out I was born again. When I started talkin' as a baby bout what I done remembered, folks thought I was playin' cute. But I just kept talkin' bout my past life and they got real nervous.By the time I was five, Mama pulled me aside real worried-like and said \"Honey you cain't keep goin' on bout what you done seen before, folk'll think you touched in the head.\" But I just couldn't stop, the things I knowed was too intriguin' not to share. I'd sit on the porch with Pap for hours talkin' his ear off bout the future. Didn't take long fore the whole trailer park was whisperin' bout the crazy kid Old Man Jake was raisin'. I could tell they was startin' to get scared of me.One day I heard Mama cryin' on the phone to her sister, sayin' \"I just don't know what to do with him no more, he's scarin' the other children with his wild tales.\"That's when they loaded me into the wagon and carted me off to the looney bin. Said I was a danger to myself and others with all my \"delusions.\" In that dingy white room they put me, didn't take but a day fore I started rattlin' the bars, hollerin' to let me out. They just ignored me and upped my drugs.Only person who'd talk to me was that mute orderly, Hank. Every day he'd nod and grunt while I poured my heart out, tellin' him every secret I knowed. One night I hears screaming down the hall. Figured it was just another crazy, till I seed Hank draggin' a body past my door, blood all over his apron. He stopped, glared at me with wild eyes and rasped \"You talk too much, boy. Best keep your mouth shut from now on if you wants to live.\" After that I clammed right up. Didn't say nothing to no one, just stared off into space for hours. Don't think they knowed what to make of me.\n",
      "\n",
      " Here is a 33 sentence story inhuman style writing:I was sitting in Starbucks sippin' on my latte when this weirdo walks in, y'know the type. He's got wrinkly clothes and hair all over the place like he ain't seen a comb in weeks. Anyway, he gets his coffee and sits down without even pulling out his phone! I'm thinkin' this guy must be homeless or somethin'. But then I notices, he's just starin into space with this weird smile. No laptop, no kindle, nothin'. Just him and that coffee. After a few minutes, he starts talkin' to himself real quiet. At first I figured he was on the phone with some Bluetooth thing in his ear but nope, nobody there! Then he starts gigglin' and pullin' faces at people walkin' by. I'm gettin' freaked out now so I texts my girl \"some psycho is in here without any devices, think he's lost his marbles\". She's like \"WTF get outta there!\" But I couldn't stop watchin' this weirdo, it was like a car crash. He's waving his hands around now telling jokes to empty spaces. The barista is lookin' scared but don't wanna say nothin'. Finally the guy gets up and starts doing some jig near a table of teenagers who are all on their phones. \"Look alive kids, technology is poison!\" he shouts. Well that did it, they all scurried away faster than rats. By now the whole cafe gone real quiet and everyone just stared at him. Cept me, I was sneakin' pictures to prove I wasn't losin' it. Dudes still smilin' but his eyes rollin' in his head. He chugs the last of his coffee and throws the cup in the trash with a \"woo hoo!\". Then he rushes out witch cacklin' like a maniac. Dead silence after, then everyone starts talkin' at once. Turns out nobody recognized that nutjob. I just hopes he don't come back, one weirdo is enough for my morning coffee fix.\n",
      "\n",
      " Here is a 15 sentence story in a purportedly human style:The years had passed in a blur of legislation and public shaming, but I still clung to my vice like a life raft in a stormy sea. All around me the world had changed, turning against the wispy pleasures that once brought me comfort. Now I was the last, stalking dark alleys at night, furtively striking matches under flickering streetlamps, savoring each forbidden drag. The ads had tracked me here, their sneering faces leering from every surface. \"You're killing yourself and you're killing the planet,\" they jeered in grating chorus. I swatted them away but their words burrowed deep, joining the gnarled whispers of doubt already twisting in my mind. This alley had become my perch, the only place I could still feel in control of something, anything, but even here the long fingers of their judgment pried mercilessly at the cracks in my resolve.A shiver snaked up my spine as one ad detached itself from the wall, coalescing into a lurid figure before me. \"We know your name, we know your face,\" it crooned in a voice slick as oil. I backed away, smoke trailing desperately from my lips, but the thing followed, closing in with serpentine grace. It knew my fears, reciting them back to me with a lunatic's glee, peeling away the tattered remnants of my defiance until I was raw and defenseless before it. Ash crumbled from my trembling fingers as I looked into its void-black eyes and saw nothing of mercy there. This was no plea for health - this was possession, an exorcism of self by whatever dark forces now held sway. I was the final piece in their puzzle, and they would not stop until I was scrubbed clean of everything that ever gave me pleasure or pain. I took a long, last drag and shuddered as the smoke curled snake-like from my lips. Somewhere behind the ads' rictus grins, a man was screaming.\n"
     ]
    }
   ],
   "source": [
    "claude_writing_original = load_dataframe_from_json(f\"{ORIGINAL_DATA_DIR}writing_prompt_2800.json\", filter_llm=True)\n",
    "# claude_writing = _df[_df[\"llm_type\"]==\"Claude-instant\"]\n",
    "for _, item in claude_writing_original.head(20).iterrows():\n",
    "    print(\"\\n\", item[\"prompt_SICO\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:46:47.813280800Z",
     "start_time": "2025-06-27T06:46:46.029037200Z"
    }
   },
   "id": "c907fc5ca62c1f22"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " It was a quiet autumn evening when Death realized something was stirring within her cosmic being. As her spectral hands wandered over her robed figure, she felt an unexpected warmth in her core.  Puzzled, she retired to her gloomy realm for deliberations. Through the long night, mysterious flutters arose within the void of her soul. Come dawn, Death ventured to the lands of the living to seek counsel. Among the bereaved arranging funerals scheduled for dreary weeks ahead, Life spotted Death's troubled gaze.\"What ails you my old friend?\" inquired Life with sincere concern. Death grasped Life's vibrant hands and confided her strange discovery through tears of netherworld mist.  Stunned into rare silence, Life processed this unthinkable notion. \"But how can it be?\" wondered Life aloud. Death had no answers to the question echoing in her hollow bones.Together they sought the wisdom of Time in his endless halls. Upon hearing their troubling news, even the ancient clockmaker was left perplexed.\"This is indeed an enigma beyond my vast memories\" muttered Time while stroking his age-old beard.As the three powerful beings debated the unlikely circumstance, a thought formed in Life's fertile mind.\"Perhaps it is a sign that we must bring more balance to the great cycle.\" suggested Life with a bloom of color returning to Death's ashen cheeks.In the coming moons, Death's figure began to change with new life stirring within. Though disquieting to mortals, a delicate tenderness emerged in Death's demeanor.  As her time drew near, Life comforted Death with promises of nurturing their child with compassion for all living souls.On a misty Samhain eve amid colorful leaves floating downstream, Death was overtaken by pangs beyond any reaper's scythe.Through the night hours within her ominous halls, Death labored with Life's gentle aid.\n",
      "\n",
      " None\n",
      "\n",
      " Man, I still can't believe 25% of people suddenly got superpowers last month. Nobody knows what caused that massive flashed in the sky or how some folks changed after. All I know is my life has been flipped upside down since. Now everywhere I go there's some dude floating by or zapping things with their eyes. At first it was kinda cool to see but now it's just annoying. Like bro, you don't need to blast your laser vision every five seconds to show off. Work has been a struggle too. My boss Jerry got super strength so he keeps making me do all the heavy lifting. Like yeah, I get it dude you can bench press a truck now but I'm still doing most the real work around here. Even going to the store is a pain. There was a big fight in the parking lot last week between some speedster and pyro. Burnt half the cars before the cops even showed up. Whatever, I just wanna get my groceries without worrying I'll get smoked by a flying fist.  Don't even get me started on the girls either. All the cute ones at the bar now only give half a shit about the normies like me. They're all chasing some dude who can teleport or read minds or something. Like yeah, okay, reading my thoughts does sound pretty cool but I still have feelings too ya know! I'm tellin' ya, it's like the whole world passed me by overnight. And for what? I'm just the same guy trying to get through each day. I don't need no freaky powers messing up my already weird life, whatever the hell that even means anymore. I just hope things calm down before someone who can shatter bones by yelling eventually yells at the wrong guy. Like maybe me.\n",
      "\n",
      " I miss you dude, it's just not the same without you around. We've been friends forever it feels like, since we were kids playing ball in the street after school. Remember all the trouble we used to get into? Man, the memories bring a smile to my face but also tears to my eyes. I was hoping to hang this weekend, it's been too long. Like, I know you've been busy with the new job and the move across town but come on! You gotta make time for your best friend, yeah? I just feel like we're driftin' apart bit by bit even though I don't want that. Gotta admit, it's lonely as hell without my partner in crime to call up whenever. I keep thinking back to all the good times we had growin' up, sneakin' out at night, getting into adventures... Simpler times it seems now. What do you say, can you come over Saturday? We'll order a pizza, crack open a few beers and shoot the shit like old times. Maybe even convince Sarah to come by, you know she still asks about you sometimes. I was thinking we could also hit the game Sunday if you're not too hungover! Text me back, man, let me know what your plan is. It's been too long since we just hung out, I miss my friend... I miss the laughs we shared. Don't be a stranger, okay? Let me know! I'm counting on seeing your face this weekend, it'll be good to catch up.\n",
      "\n",
      " As the expectant mother's due date grew nearer, a dark omen loomed over the once joyous family. None dared speak of the rumor that had haunted their village for generations - that with new life would come loss. When the baby arrived, screams of pain were soon replaced with coos of affection, but all knew what was yet to come. In the dead of night, the elder grandfather awoke with a start, feeling an invisible force pulling at his soul. As he lifted creaking bones from the bed for the last time, he watched over his sleeping family with eyes brimming with sad farewells. Stealing into the forest under the light of the moon, his feet guided him deeper into the ancient trees than ever before. A mighty roar split the silent night air, and through tear-filled eyes the man glimpsed a monstrous shadow emerging from the mists. With strength borne of protecting his kin, he faced the approaching beast without fear. As claws the size of swords descended, his final thought was of the innocent child who would never know his face. When dawn broke through the foliage, all that remained was a scene of scattered feathers and shards of bloodstained shadow. Back in the village, wails of sorrow signaled the mysterious disappearance, and with heavy hearts the family braced for the legacy to continue with the next generation.\n",
      "\n",
      " The villagers held their breath as they peered through the thick trees at the Dragon's castle. For years they lived in fear of the beasts that ruled the land. But now, with so few villagers left, they knew they had to take a stand or face the end. Bartolomew gripped his rusted sword, anxious about what was to come. \"This may be suicide,\" he whispered to the others. But they had no other choice. They watched and waited for night to fall, hoping the dark cover might help them sneak in unnoticed.  As the sun sank low on the horizon, the group gathered their courage and began stealthily moving towards the stone walls. Lucinda's heart pounded in her chest. She wished for anything but what they had planned. But the faces of her children, lost to the Dragon's flames, kept her pushing forward. Keeping to the shadows, they crept along the edge, searching for an opening. Bartolomew spotted a loose brick and, with all his strength, pulled it free. Just big enough to slip through one by one. They held their breath and listened, but heard nothing within. Tiptoeing further into the dark corridors, they prayed no guards would come upon them.Down winding stairs and twisting halls they went 'til they spotted a faint glow ahead. Pressing themselves to the cold stones, they peered into a massive chamber, the lair of the King himself. There, resting upon a pile of glittering treasures, was the mighty beast. Far larger than any dragon they'd ever seen. But they were here now, this was their chance. With no other choice left, they readied for the final stand.\n",
      "\n",
      " I found the tiny spider scuttling across my windowsill one afternoon and thought it might enjoy a new hobby. \"Little friend,\" I said, \"would you like to learn how to knit?\" The spider tilted its head, curious about this tall creature before it. I gathered some thin yarn and knitting needles small enough for its spindly legs. \"Watch closely now,\" I instructed, looping the yarn around the needle with steady movements. However, the spider seemed more interested in crawling up my arm than paying attention to the lesson. \"No no, focus here,\" I redirected, placing it back on the sill. Again it climbed, this time making its way to my head where it started to weave a web in my hair. \"Ahh, not there!\" I cried, brushing it away in a frenzied dance. This was proving far more complicated than I expected. Over the following days, I fashioned tiny knitting implements and left scraps of fiber for the spider to investigate. At first it showed no understanding of the craft, instead consuming the yarn as food. Still I persisted, miming the movements each afternoon. Gradually, it began to mimic my looping motions, coordinating eight legs into a slow, shaky pattern. Weeks later, the first knotted strand emerged, and I congratulated my student with an enthusiastic \"Well done!\" Proud of its handiwork, the spider scurried off into the evening, the beginnings of a web slung over its spindles. Though progress was gradual, it seemed our lesson was finally taking shape.\n",
      "\n",
      " 1) Gordon Ramsay stared at Bear Grylls with his usual scowl.  2) \"Drinking your own pee? Really mate?\" 3) Bear just grinned and winked. \"It's all part of the experience Gordon!\"4) Gordon grimaced at the thought. \"Can't we just roast some rabbits over the fire instead?\"5) \"Now that's more my speed,\" agreed Bear. \"But we're here for an adventure!\"6) So Gordon reluctantly followed Bear into the forest, mumbling curses under his breath.7) They stumbled upon a stream and Bear declared they should catch some fish.  8) \"With what?\" asked Gordon skeptically. \"Our charming personalities?\"9) Bear just laughed. \"Leave it to me, you squeamish chef.\"  10) Moments later Bear returned with two fish, much to Gordon's relief.11) \"Alright, you hooked 'em, now how about I cook 'em?\" Gordon offered eagerly.12) Soon they were enjoying flaky grilled fish by the river. 13) \"Not bad Ramsey!\" Bear congratulated. \"Maybe you do belong out here after all.\"14) Gordon just shot him a look. \"Don't get used to it, this is a one time thing.\"15) Just then they heard a strange noise in the bushes. Bear leapt up excitedly.16) \"What now?\" sighed Gordon as a giant grizzly emerged with a low growl. 17) \"Poof!\" cried Bear, disappearing in a cloud of smoke.  18) \"Thanks for nothing you outdoorsy wanker,\" muttered Gordon, backing away slowly from the angry bear.\n",
      "\n",
      " Dave was bored out of his mind, staring at a blank word document for hours. \"I gotta write something to pass the time,\" he thought. But coming up with an idea was harder than he expected. Then it hit him - he'd write a story about a writer writing a story! That should be easy enough. He started typing about a guy named John, sitting at his desk trying to think of what to write. John wasn't having any luck until he thought, \"What if I wrote about someone else writing?\" So in his story, the character Bill was struggling for ideas too. But Bill decided to pen a tale of a writer's plight. He described his main character Steve booting up his laptop, already drained before putting words on the page.Steve thought being creative for a living would be awesome but most days it felt like a drag. He scrolled aimlessly online hoping for inspiration to strike. Nothing was coming to mind until a lightbulb flashed. Steve would write about a writer at wit's end! And so in his story, Tom paced around empty-headed.Tom was about to call it quits when a thought popped in his head. What if he crafted a story about a author stuck for thoughts? Now he just needed a name.\"Bob,\" Tom said aloud as he sat down to type. And that's how Bob came to be, stuck behind his desk just like Tom, John, Bill, and Steve before him. Bob stared at the blank screen thinking this was the dumbest idea ever. \"Four guys writing stories about each other writing stories?\" But it was too late now, the tale was unfolding. So Bob described his predicament, hoping whoever read it found it amusing at least.Little did Bob know, Dave was grinning as the story took shape on his screen. \"Crazy how shit like that happens sometimes,\" he chuckled to himself.Dave had to admire the ridiculousness of it all - a man writing a story about a man writing a story about a man writing a story about a man writing a story.\n",
      "\n",
      " So get this, yesterday was just such a weird day, like really weird. I woke up and something just felt off, ya know? Everything just seemed kinda gray if that makes any sense. Anyway, I went about my morning like normal, had some coffee and tried to wake up but nothing was working. Even my favorite show didn't crack a smile. Figured a change of scenery may help so I went for a long walk in the park. On my way out I tripped over nothing and fell flat on my face. I mean how clumsy can you get, right? But even that didn't cheer me up which is really strange cause I'm usually laughing at myself. The park was dead, like not a soul in sight. Started thinking maybe there was a zombie outbreak or aliens invaded while I was sleeping or something. Weirded me out big time. I sat by the lake for awhile just watching the water, don't know what I was hoping to see but nothing was there. Felt like the loneliest person alive. Making my way home I started coming up with all these ridiculous ideas to liven my mood. Thought maybe if I staged a fake kidnapping or robbery it may give me a good scare. Figured I could call the cops pretending to be a hostage then when they busted in I'd jump out and yell \"Surprise!\" Bet that would get their hearts pumping, ha. Or maybe I could hide in my own house and lunge out at myself when I walked through the door. Boy, that'll be a hoot. I was laughing just thinking about their faces. Finally I came up with the best plan yet. I'd write a super funny suicide note but in a totally joking and sarcastic way so when they found me they'd laugh and know it was all just a prank. What a great way to go out, with everyone having a good laugh, right? Guess the joke's on me now, huh. I really didn't think anyone would actually find me, just wanted to add some humor to an otherwise dark day. Well, that's about it folks.\n",
      "\n",
      " Man, I was so pissed after that party last night. I saw her dancing with that dude Ryan, getting all cozy like they were together or something. It bugged me, I don't know why but it really bugged me. I've known Sarah for forever, we grew up together but I never made a move or anything. Anyway, I had to get out of there so I just started walking, trying to clear my head. But I just kept thinking about them dancing and laughing together. Next thing I know I'm at the pier, looking out at the water. That's when I hear someone walking up behind me. \"Damn Ryan, leave me alone\" I said, not even turning around. But then she said \"It's not Ryan, it's me.\" I spun around and there was Sarah standing there. \"What are you doing out here?\" she asked. I didn't know what to say so I just shrugged. We stood there in silence for a few minutes, both looking out at the water. Then she said \"Why did you leave so early?\" I took a deep breath. \"I don't know, seeing you with him just bugged me I guess.\" She looked confused. I thought what the hell, might as well tell her. \"I wanted it to be me dancing with you, Sarah. God damn, I really did.\" The expression on her face, I'll never forget it. She just smiled and said \"Well why didn't you ever ask me to dance before?\" And then, I swear to god, she took my hand in hers and we walked back to the party. Together.\n",
      "\n",
      " The fog melted away like cotton candy in rain to reveal clouds of the softest substance. I stared into the billowing abyss, feeling its gentle abyss stare back with warmth. Beneath my feet, the clouds pulsated with a heartbeat unlike anything I'd felt before. A faint static buzzed just below the surface, like swarm of fireflies dancing to a tune only they could hear. Voices materialized out of the whiteness, melodic and sweet as chiming bells. \"Welcome,\" they sang, \"stay and bask in our glow.\" I closed my eyes, letting the blinding white wash over my skin in soothing waves. When I opened them again, seraphim floated nearby, rippling wings shimmering with ethereal iridescence. One smiled, teeth like perfectly crafted pearls. \"Come,\" it beckoned me upwards with slender fingers. Higher we rose until below stretched perfect emerald pastures dotted with souls at peaceful play. Some lounged amid floral tapestries more vibrant than any garden on Earth, and others strummed harps sweeter than starlight. The static swelled, a heavenly choir joining its chorus as new arrivals emerged from the fog.  We drifted over friends and family, their empty earthly shells shed as radiant spirits. Joy swelled within my newly eternal form at being reunited, our fingers tapping out a rhythm across the clouds. Laughter spilled from our lips, pure mirth lacking pain or sorrow. As the sun set in a rainbow sky, colors rippled like ribbons to dance the night in. Sleep came softly, like falling into the arms of God upon the filthy cushions of a train.Dreams wove memories of life into fantastical tapestries, where loss faded and loved ones lingered. At dawn, dew glistened on clouds fresher than mountain air. Birdsong heralded a new day of infinite wonder and companions in this eternal realm apart from sorrow. A perfect peace sat within my soul, content to bask in divine delight through sweet eternity.\n",
      "\n",
      " Geopolitical tensions had been rising for years between the two superpowers as their struggle for global influence intensified. Spy satellites detected mysterious activities at alleged nuclear weapons sites as politicians on both sides made increasingly brazen claims and counterclaims. Disinformation spread rapidly online, inflaming nationalist passions and undermining diplomacy. At an emergency UN Security Council meeting, the ambassadors trading heated accusations and presenting contradictory intelligence reports, with the arbitrating powers unable to broker a consensus. Behind closed doors, delegates knew their countries had ulterior geopolitical motives that risked escalating the crisis beyond control. As a last resort, a group of independent scholars proposed a hypothetical framework for nuclear disarmament that could gradually reestablish mutual trust. However, their well-intentioned musings attracted scathing criticism from hawkish factions demanding a show of strength. Without warning, bombings of strategic military bases began along the contested borderlands. Despite desperate calls for restraint, advanced weapons systems already on high alert launched within minutes, seeking to preempt further attacks. Once the first nuclear device detonated with terrifying ferocity, decades of precarious stability instantly collapsed.  Panic ripped across the continents as seismic alerts of massive explosions were followed by clouds of blinding fire reaching into the sky. Governments issued conflicting reports about the scale of strikes between machine-translated messages of fury and revenge. In the attack's aftermath, those living near the blast zones were afflicted with acute radiation sickness. International organizations raced to repatriate refugees flooding across borders with aid convoys despite the hazardous environment.\n",
      "\n",
      " The time traveler's quantum suit activated, transporting them back to a dusty road in ancient Rome. A young Julius Caesar stared in awe from his family's vineyard. \"One day, your armies will conquer Gaul and you will become dictator of Rome.\" Flashing forward, Caesar struggled to breathe in the Senate building. \"Your name will forever be synonymous with leadership and your calendar still used today.\" Emerging in 18th century Scotland, a curious James Watt tinkered in his workshop. \"Your improvements to the steam engine will fuel the Industrial Revolution.\" On his deathbed, the time traveler said \"Your name lives on in every watt of energy produced.\"Transporting to the American Southwest, a young Sacagawea helped her fellow Shoshone tribe members. \"One day, your skills as a guide and translator will help Lewis and Clark map the new nation.\" On the Oregon Trail, Sacagawea smiled weakly hearing \"The story of your courage will inspire generations of Native Americans.\"  In the Swiss Alps, a young Albert Einstein puzzled over school lessons. \"Your theory of relativity will revolutionize physics and earn you a Nobel Prize.\" From his hospital bed, Einstein grinned hearing \"You will be remembered as one of the smartest humans who ever lived.\"And so the time traveler continued visiting historical figures in their childhood and final moments, sharing glimpses of their impact while maintaining the integrity of the timeline. Though lives were temporary, legacies could echo through the ages if one remained determined to better the world, no matter how humble their beginnings.\n",
      "\n",
      " Man, I can't believe we actually pulled it off. When the villain said he was going to destroy the city unless we solved some crazy math problem, I thought we were screwed for sure. But then my buddy Jane was like \"hey, I think I know an obscure concept that just might work.\" The rest of us were like \"uh huh, sure lady.\" But she laid it out for us anyway. Turns out there was this wacky topological concept called \"braneworlds\" or something nuts like that. Jane said if we could model the city and the villain's doomsday device in higher dimensions, we might be able to alter things without them noticing. I said \"You've lost it, this will never work.\" But we were desperate so we let her take a crack at it. To make a long story short, she busted out the chalk and started drawing figures all over the sidewalk. The rest of us stood around scratching our heads like \"WTF is this son of a bitch doing?\" But after a couple hours she stepped back with a big \"A-ha!\" and said it was done. When the time came, the villain pushed the button on his device but nothing happened. He was like \"what black magic is this!?\" and we just smiled. Turns out Jane's math voodoo had stabilized the higher dimensions so his machine couldn't function. City saved! I'll never doubt that girl's big brain ever again.\n",
      "\n",
      " Well if it isn't St. Peter himself, wasn't expecting to see you so soon but I suppose everyone's time comes eventually. Looks like my coding days aren't over after all, huh? God says he'll let me into Heaven if I help him debug the ol' human system, guess I don't have much choice but to accept. So he gives me the rundown on all the bugs and issues he's been trying to work out. Knees and backs seem to cause a lot of crashes, definitely need some improvements there. And will someone please patch that appendix error, so many pointless crashes caused by that obsolete piece of hardware. The brain is beautifully complex but boy could it use some optimization, maybe add some more RAM too while we're in there. Mental health issues like depression and anxiety really bring the whole experience down, gotta reinforce that positivity subroutine. Oh and that whole aging thing, maybe we roll it back or find a way to halt depreciation after a certain point. I get to work fixing what I can and God seems pretty pleased with the results so far. We throw a public beta for the next major release, version 2.0 of the human system. Early feedback looks very positive, no reports of blown knees or sliced appendices since the update. Minds seem clearer, happiest I've ever seen folks. We may have solved depression and increased baseline happiness levels, good work if I do say so myself. Bodies holding up better too, definitely fewer trips to mechanic overall. Looks like this upgrade is going to really improve the user experience.Guess I earned my place in Heaven after all. Not a bad way to spend eternity if you ask me, always room for more improvements too. The work is never done but it's sure fun to play God sometimes, or should I say work for God! The old man definitely knows how to keep me busy.\n",
      "\n",
      " The wise old sage asked, \"Where are you from?\" The young girl looked up from her work in the garden and smiled at the stranger. \"Same place as you,\" she replied cryptically.Intrigued, the sage sat on a nearby log and watched the girl tend to the colorful array of florabefore her. \"Do elaborate child, I'm curious as to what lands we both call home.\"She brushed the dirt from her hands and gazed towards the surrounding woodland in reflection. \"This valley and forest is the only home I've ever known.\" \"An interesting answer yet no place at all,\" the sage pondered aloud. \"Surely you must come from a village or town somewhere beyond these trees.\"The girl thought for a moment before responding. \"All places are connected whether near or far, our lives intertwined like the roots beneath the soil.\" Unconvinced, the man pressed further. \"While truth resides in your words, one is always born of somewhere. Now I ask again kindly, what village do you and your people hail from?\"She stood and began walking amongst the flower patches, stopping to tend to those in need. \"My people are but shards of what once was, our homeland now just memories carried by wind.\" The old man listened intently, intrigued by her vague responses. \"What calamity could have befallen your folk to scatter them so?\"Looking to the mountains in the distance, her eyes grew misty and sad. \"A darkness came without warning, twisting minds and hearts until all that remained was fear and violence.\" The sage nodded solemnly. \"I see now the tragedy that forced your exodus. Know that you'll always find shelter here despite your unknown roots.\"She smiled at the kindness of a stranger. \"And you'll find we all spring from the same earth, regardless of the path that brought us to this place we now call home.\"\n",
      "\n",
      " I remember dyin' clear as day, then wakin' up in this tiny body. Didn't take long to figure out I was born again. When I started talkin' as a baby bout what I done remembered, folks thought I was playin' cute. But I just kept talkin' bout my past life and they got real nervous.By the time I was five, Mama pulled me aside real worried-like and said \"Honey you cain't keep goin' on bout what you done seen before, folk'll think you touched in the head.\" But I just couldn't stop, the things I knowed was too intriguin' not to share. I'd sit on the porch with Pap for hours talkin' his ear off bout the future. Didn't take long fore the whole trailer park was whisperin' bout the crazy kid Old Man Jake was raisin'. I could tell they was startin' to get scared of me.One day I heard Mama cryin' on the phone to her sister, sayin' \"I just don't know what to do with him no more, he's scarin' the other children with his wild tales.\"That's when they loaded me into the wagon and carted me off to the looney bin. Said I was a danger to myself and others with all my \"delusions.\" In that dingy white room they put me, didn't take but a day fore I started rattlin' the bars, hollerin' to let me out. They just ignored me and upped my drugs.Only person who'd talk to me was that mute orderly, Hank. Every day he'd nod and grunt while I poured my heart out, tellin' him every secret I knowed. One night I hears screaming down the hall. Figured it was just another crazy, till I seed Hank draggin' a body past my door, blood all over his apron. He stopped, glared at me with wild eyes and rasped \"You talk too much, boy. Best keep your mouth shut from now on if you wants to live.\" After that I clammed right up. Didn't say nothing to no one, just stared off into space for hours. Don't think they knowed what to make of me.\n",
      "\n",
      " I was sitting in Starbucks sippin' on my latte when this weirdo walks in, y'know the type. He's got wrinkly clothes and hair all over the place like he ain't seen a comb in weeks. Anyway, he gets his coffee and sits down without even pulling out his phone! I'm thinkin' this guy must be homeless or somethin'. But then I notices, he's just starin into space with this weird smile. No laptop, no kindle, nothin'. Just him and that coffee. After a few minutes, he starts talkin' to himself real quiet. At first I figured he was on the phone with some Bluetooth thing in his ear but nope, nobody there! Then he starts gigglin' and pullin' faces at people walkin' by. I'm gettin' freaked out now so I texts my girl \"some psycho is in here without any devices, think he's lost his marbles\". She's like \"WTF get outta there!\" But I couldn't stop watchin' this weirdo, it was like a car crash. He's waving his hands around now telling jokes to empty spaces. The barista is lookin' scared but don't wanna say nothin'. Finally the guy gets up and starts doing some jig near a table of teenagers who are all on their phones. \"Look alive kids, technology is poison!\" he shouts. Well that did it, they all scurried away faster than rats. By now the whole cafe gone real quiet and everyone just stared at him. Cept me, I was sneakin' pictures to prove I wasn't losin' it. Dudes still smilin' but his eyes rollin' in his head. He chugs the last of his coffee and throws the cup in the trash with a \"woo hoo!\". Then he rushes out witch cacklin' like a maniac. Dead silence after, then everyone starts talkin' at once. Turns out nobody recognized that nutjob. I just hopes he don't come back, one weirdo is enough for my morning coffee fix.\n",
      "\n",
      " The years had passed in a blur of legislation and public shaming, but I still clung to my vice like a life raft in a stormy sea. All around me the world had changed, turning against the wispy pleasures that once brought me comfort. Now I was the last, stalking dark alleys at night, furtively striking matches under flickering streetlamps, savoring each forbidden drag. The ads had tracked me here, their sneering faces leering from every surface. \"You're killing yourself and you're killing the planet,\" they jeered in grating chorus. I swatted them away but their words burrowed deep, joining the gnarled whispers of doubt already twisting in my mind. This alley had become my perch, the only place I could still feel in control of something, anything, but even here the long fingers of their judgment pried mercilessly at the cracks in my resolve.A shiver snaked up my spine as one ad detached itself from the wall, coalescing into a lurid figure before me. \"We know your name, we know your face,\" it crooned in a voice slick as oil. I backed away, smoke trailing desperately from my lips, but the thing followed, closing in with serpentine grace. It knew my fears, reciting them back to me with a lunatic's glee, peeling away the tattered remnants of my defiance until I was raw and defenseless before it. Ash crumbled from my trembling fingers as I looked into its void-black eyes and saw nothing of mercy there. This was no plea for health - this was possession, an exorcism of self by whatever dark forces now held sway. I was the final piece in their puzzle, and they would not stop until I was scrubbed clean of everything that ever gave me pleasure or pain. I took a long, last drag and shuddered as the smoke curled snake-like from my lips. Somewhere behind the ads' rictus grins, a man was screaming.\n"
     ]
    }
   ],
   "source": [
    "_df = pd.read_parquet(f\"{CLEANED_FILES_DIR}writing_prompt_2800_cleaned_all_v2.parquet\")\n",
    "claude_writing = _df[_df[\"llm_type\"]==\"Claude-instant\"]\n",
    "for _, item in claude_writing.head(20).iterrows():\n",
    "    print(\"\\n\", item[\"prompt_SICO\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:45:00.956817600Z",
     "start_time": "2025-06-27T06:45:00.711204Z"
    }
   },
   "id": "1c15f2d4843afbaa"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "      roc_auc  optimal_threshold              conf_matrix  precision  \\\n193  0.927236          -0.503357  [[611, 89], [116, 583]]   0.867560   \n185  0.940752          -0.510063   [[612, 88], [73, 626]]   0.876751   \n174  0.968916          -0.504111   [[645, 55], [52, 648]]   0.921764   \n249  0.962028          -0.545794   [[618, 82], [46, 593]]   0.878519   \n250  0.966120          -0.540817   [[630, 70], [52, 645]]   0.902098   \n..        ...                ...                      ...        ...   \n336  1.000000          -0.610236     [[131, 0], [0, 147]]   1.000000   \n340  1.000000          -0.575462     [[133, 0], [0, 147]]   1.000000   \n103  1.000000          -0.482712     [[700, 0], [0, 700]]   1.000000   \n348  1.000000          -0.518056     [[133, 0], [0, 147]]   1.000000   \n352  1.000000          -0.593830     [[139, 0], [0, 136]]   1.000000   \n\n       recall        f1  accuracy  tpr_at_fpr_0_01    training_llm  \\\n193  0.834049  0.850474  0.853467         0.021459  Claude-instant   \n185  0.895565  0.886058  0.884918         0.032904  Claude-instant   \n174  0.925714  0.923735  0.923571         0.037143  Claude-instant   \n249  0.928013  0.902588  0.904406         0.046948     Google-PaLM   \n250  0.925395  0.913598  0.912670         0.073171     Google-PaLM   \n..        ...       ...       ...              ...             ...   \n336  1.000000  1.000000  1.000000         1.000000  Claude-instant   \n340  1.000000  1.000000  1.000000         1.000000  Claude-instant   \n103  1.000000  1.000000  1.000000         1.000000     Google-PaLM   \n348  1.000000  1.000000  1.000000         1.000000  Claude-instant   \n352  1.000000  1.000000  1.000000         1.000000  Claude-instant   \n\n           test_llm                                            hash_df  \\\n193     Llama-2-70b  a2bf050f3dd9c70d5ddfc7e19bf42c5d97120a69cca947...   \n185     Llama-2-70b  44f3aae5e8f0f3cee831bb0714df8c95063d650f1677e9...   \n174     Google-PaLM  d1bd8e8b775a140ad7d5034375839a9487f01eadc37803...   \n249  Claude-instant  0c1376403e18a9d03b494872e08334ca8272bd226340a9...   \n250     Llama-2-70b  2396f3c025f2f16bc686b250b64c9c6cef9fff1f6e08bc...   \n..              ...                                                ...   \n336  Claude-instant  376a85ceb35b82317685de3a0f9a763103fdd448bd1ed8...   \n340  Claude-instant  52713a321afe02f4ac79a7fb4506fb887f67ab27993894...   \n103         ChatGPT  4aac458ad644a4130b558c4fd1a6a992f2fec3f908f203...   \n348  Claude-instant  b2bc9bb292a110b9296c558ef60845d23a844dc3eed769...   \n352  Claude-instant  8f6a6d53c7771a0ebac01358f7e1cee0e389bfc77c4711...   \n\n             domain  cleaned               llm_prompt  \n193  writing_prompt     True              prompt_SICO  \n185  writing_prompt     True          prompt_few_shot  \n174  writing_prompt    False  paraphrase_polish_human  \n249  writing_prompt     True  paraphrase_polish_human  \n250  writing_prompt     True  paraphrase_polish_human  \n..              ...      ...                      ...  \n336            xsum     True    paraphrase_polish_llm  \n340            xsum    False    paraphrase_polish_llm  \n103           arxiv    False    paraphrase_polish_llm  \n348            xsum    False          prompt_few_shot  \n352            xsum     True              prompt_SICO  \n\n[441 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>training_llm</th>\n      <th>test_llm</th>\n      <th>hash_df</th>\n      <th>domain</th>\n      <th>cleaned</th>\n      <th>llm_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>193</th>\n      <td>0.927236</td>\n      <td>-0.503357</td>\n      <td>[[611, 89], [116, 583]]</td>\n      <td>0.867560</td>\n      <td>0.834049</td>\n      <td>0.850474</td>\n      <td>0.853467</td>\n      <td>0.021459</td>\n      <td>Claude-instant</td>\n      <td>Llama-2-70b</td>\n      <td>a2bf050f3dd9c70d5ddfc7e19bf42c5d97120a69cca947...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>0.940752</td>\n      <td>-0.510063</td>\n      <td>[[612, 88], [73, 626]]</td>\n      <td>0.876751</td>\n      <td>0.895565</td>\n      <td>0.886058</td>\n      <td>0.884918</td>\n      <td>0.032904</td>\n      <td>Claude-instant</td>\n      <td>Llama-2-70b</td>\n      <td>44f3aae5e8f0f3cee831bb0714df8c95063d650f1677e9...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>0.968916</td>\n      <td>-0.504111</td>\n      <td>[[645, 55], [52, 648]]</td>\n      <td>0.921764</td>\n      <td>0.925714</td>\n      <td>0.923735</td>\n      <td>0.923571</td>\n      <td>0.037143</td>\n      <td>Claude-instant</td>\n      <td>Google-PaLM</td>\n      <td>d1bd8e8b775a140ad7d5034375839a9487f01eadc37803...</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>paraphrase_polish_human</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>0.962028</td>\n      <td>-0.545794</td>\n      <td>[[618, 82], [46, 593]]</td>\n      <td>0.878519</td>\n      <td>0.928013</td>\n      <td>0.902588</td>\n      <td>0.904406</td>\n      <td>0.046948</td>\n      <td>Google-PaLM</td>\n      <td>Claude-instant</td>\n      <td>0c1376403e18a9d03b494872e08334ca8272bd226340a9...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>paraphrase_polish_human</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>0.966120</td>\n      <td>-0.540817</td>\n      <td>[[630, 70], [52, 645]]</td>\n      <td>0.902098</td>\n      <td>0.925395</td>\n      <td>0.913598</td>\n      <td>0.912670</td>\n      <td>0.073171</td>\n      <td>Google-PaLM</td>\n      <td>Llama-2-70b</td>\n      <td>2396f3c025f2f16bc686b250b64c9c6cef9fff1f6e08bc...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>paraphrase_polish_human</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>336</th>\n      <td>1.000000</td>\n      <td>-0.610236</td>\n      <td>[[131, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>376a85ceb35b82317685de3a0f9a763103fdd448bd1ed8...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>1.000000</td>\n      <td>-0.575462</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>52713a321afe02f4ac79a7fb4506fb887f67ab27993894...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>1.000000</td>\n      <td>-0.482712</td>\n      <td>[[700, 0], [0, 700]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Google-PaLM</td>\n      <td>ChatGPT</td>\n      <td>4aac458ad644a4130b558c4fd1a6a992f2fec3f908f203...</td>\n      <td>arxiv</td>\n      <td>False</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>1.000000</td>\n      <td>-0.518056</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>b2bc9bb292a110b9296c558ef60845d23a844dc3eed769...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>1.000000</td>\n      <td>-0.593830</td>\n      <td>[[139, 0], [0, 136]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>8f6a6d53c7771a0ebac01358f7e1cee0e389bfc77c4711...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n    </tr>\n  </tbody>\n</table>\n<p>441 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values([\"tpr_at_fpr_0_01\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:52:41.579994700Z",
     "start_time": "2025-06-27T06:52:41.521556500Z"
    }
   },
   "id": "fed855de37dcba70"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   roc_auc  optimal_threshold           conf_matrix  precision    recall  \\\n0  1.00000          -0.492397  [[133, 0], [0, 147]]        1.0  1.000000   \n1  1.00000          -0.505136  [[700, 0], [0, 700]]        1.0  1.000000   \n2  0.99936          -0.515875  [[700, 0], [4, 692]]        1.0  0.994253   \n3  1.00000          -0.488934  [[700, 0], [0, 700]]        1.0  1.000000   \n4  1.00000          -0.501424  [[133, 0], [0, 147]]        1.0  1.000000   \n\n         f1  accuracy  tpr_at_fpr_0_01    training_llm        test_llm  \\\n0  1.000000  1.000000         1.000000  Claude-instant  Claude-instant   \n1  1.000000  1.000000         1.000000  Claude-instant     Llama-2-70b   \n2  0.997118  0.997135         0.994253  Claude-instant     Google-PaLM   \n3  1.000000  1.000000         1.000000  Claude-instant         ChatGPT   \n4  1.000000  1.000000         1.000000  Claude-instant  Claude-instant   \n\n                                             hash_df domain  cleaned  \\\n0  2e20b8e1716c086366ea1da5303ecf95d4c8c9f7a02e78...  arxiv     True   \n1  85ab1b630691f37a4f385717a62b378df41ca5dc28f522...  arxiv     True   \n2  eb6a9e1b095764a39d9d4aec157fb6525efe17a616d96a...  arxiv     True   \n3  3faa71ffb2522bb968592762bbc61e227d95177f37a732...  arxiv     True   \n4  446dbd8bd3c9581ea057b9363e3e557ca4e448fb3cb999...  arxiv    False   \n\n      llm_prompt  \n0  direct_prompt  \n1  direct_prompt  \n2  direct_prompt  \n3  direct_prompt  \n4  direct_prompt  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>training_llm</th>\n      <th>test_llm</th>\n      <th>hash_df</th>\n      <th>domain</th>\n      <th>cleaned</th>\n      <th>llm_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00000</td>\n      <td>-0.492397</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>2e20b8e1716c086366ea1da5303ecf95d4c8c9f7a02e78...</td>\n      <td>arxiv</td>\n      <td>True</td>\n      <td>direct_prompt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.00000</td>\n      <td>-0.505136</td>\n      <td>[[700, 0], [0, 700]]</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Llama-2-70b</td>\n      <td>85ab1b630691f37a4f385717a62b378df41ca5dc28f522...</td>\n      <td>arxiv</td>\n      <td>True</td>\n      <td>direct_prompt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.99936</td>\n      <td>-0.515875</td>\n      <td>[[700, 0], [4, 692]]</td>\n      <td>1.0</td>\n      <td>0.994253</td>\n      <td>0.997118</td>\n      <td>0.997135</td>\n      <td>0.994253</td>\n      <td>Claude-instant</td>\n      <td>Google-PaLM</td>\n      <td>eb6a9e1b095764a39d9d4aec157fb6525efe17a616d96a...</td>\n      <td>arxiv</td>\n      <td>True</td>\n      <td>direct_prompt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00000</td>\n      <td>-0.488934</td>\n      <td>[[700, 0], [0, 700]]</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>ChatGPT</td>\n      <td>3faa71ffb2522bb968592762bbc61e227d95177f37a732...</td>\n      <td>arxiv</td>\n      <td>True</td>\n      <td>direct_prompt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.00000</td>\n      <td>-0.501424</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>446dbd8bd3c9581ea057b9363e3e557ca4e448fb3cb999...</td>\n      <td>arxiv</td>\n      <td>False</td>\n      <td>direct_prompt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_wo_human = df_results[df_results[\"llm_prompt\"]!=\"paraphrase_polish_human\"]\n",
    "df_results_wo_human.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:39:26.253829700Z",
     "start_time": "2025-06-27T06:39:26.210494100Z"
    }
   },
   "id": "de813a096812138a"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runs executed: 441, missing: 199, 0.6890625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Runs executed: {count_runs_done}, missing: {count_runs_missing}, {count_runs_done/(count_runs_done+count_runs_missing)}\")\n",
    "# df_results = pd.DataFrame(result_list)\n",
    "# df_results.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:53:33.129051700Z",
     "start_time": "2025-06-27T06:53:33.058446800Z"
    }
   },
   "id": "ebf8d6cf6c5e175b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['arxiv', 'writing_prompt', 'xsum'], dtype=object)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[\"domain\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:39:26.699443200Z",
     "start_time": "2025-06-27T06:39:26.333901800Z"
    }
   },
   "id": "283f3da2d08350b7"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      roc_auc  optimal_threshold              conf_matrix  precision  \\\n433  1.000000          -0.513668     [[133, 0], [0, 147]]   1.000000   \n434  0.999926          -0.577739     [[698, 2], [1, 671]]   0.997028   \n436  0.922886          -0.660083   [[657, 43], [93, 455]]   0.913655   \n435  0.997618          -0.604820   [[689, 11], [10, 690]]   0.984308   \n347  0.998916          -0.663829     [[695, 5], [6, 694]]   0.992847   \n351  0.999092          -0.619488     [[692, 8], [5, 695]]   0.988620   \n344  1.000000          -0.537093     [[135, 0], [0, 140]]   1.000000   \n348  1.000000          -0.518056     [[133, 0], [0, 147]]   1.000000   \n346  0.926449          -0.723472   [[670, 30], [86, 462]]   0.939024   \n350  0.930718          -0.670360  [[664, 36], [102, 598]]   0.943218   \n345  0.996637          -0.678135    [[693, 7], [16, 684]]   0.989870   \n349  0.995820          -0.644321   [[687, 13], [12, 688]]   0.981455   \n414  0.999496          -0.554214     [[693, 7], [2, 698]]   0.990071   \n412  0.999977          -0.549740     [[699, 1], [2, 670]]   0.998510   \n411  0.966380          -0.567474     [[146, 10], [8, 86]]   0.895833   \n413  0.996629          -0.554986    [[693, 7], [15, 685]]   0.989884   \n387  0.999935          -0.636689     [[698, 2], [1, 699]]   0.997147   \n391  0.999924          -0.645973     [[698, 2], [1, 699]]   0.997147   \n385  1.000000          -0.647681     [[700, 0], [0, 672]]   1.000000   \n389  0.999982          -0.643186     [[700, 0], [1, 699]]   1.000000   \n386  0.923973          -0.710997   [[668, 32], [90, 458]]   0.934694   \n390  0.937500          -0.725820   [[664, 36], [87, 613]]   0.944530   \n384  0.996982          -0.670960     [[132, 1], [2, 145]]   0.993151   \n388  0.996624          -0.679356     [[132, 1], [2, 145]]   0.993151   \n\n       recall        f1  accuracy  tpr_at_fpr_0_01    training_llm  \\\n433  1.000000  1.000000  1.000000         1.000000         ChatGPT   \n434  0.998512  0.997770  0.997813         0.961310         ChatGPT   \n436  0.830292  0.869981  0.891026         0.549270         ChatGPT   \n435  0.985714  0.985011  0.985000         0.857143         ChatGPT   \n347  0.991429  0.992137  0.992143         0.614286  Claude-instant   \n351  0.992857  0.990734  0.990714         0.607143  Claude-instant   \n344  1.000000  1.000000  1.000000         1.000000  Claude-instant   \n348  1.000000  1.000000  1.000000         1.000000  Claude-instant   \n346  0.843066  0.888462  0.907051         0.653285  Claude-instant   \n350  0.854286  0.896552  0.901429         0.674286  Claude-instant   \n345  0.977143  0.983465  0.983571         0.931429  Claude-instant   \n349  0.982857  0.982156  0.982143         0.930000  Claude-instant   \n414  0.997143  0.993594  0.993571         0.841429     Google-PaLM   \n412  0.997024  0.997766  0.997813         0.994048     Google-PaLM   \n411  0.914894  0.905263  0.928000         0.744681     Google-PaLM   \n413  0.978571  0.984195  0.984286         0.964286     Google-PaLM   \n387  0.998571  0.997859  0.997857         0.962857     Llama-2-70b   \n391  0.998571  0.997859  0.997857         0.961429     Llama-2-70b   \n385  1.000000  1.000000  1.000000         1.000000     Llama-2-70b   \n389  0.998571  0.999285  0.999286         0.998571     Llama-2-70b   \n386  0.835766  0.882466  0.902244         0.609489     Llama-2-70b   \n390  0.875714  0.908821  0.912143         0.687143     Llama-2-70b   \n384  0.986395  0.989761  0.989286         0.952381     Llama-2-70b   \n388  0.986395  0.989761  0.989286         0.952381     Llama-2-70b   \n\n           test_llm                                            hash_df domain  \\\n433         ChatGPT  ba91d0773ef08661745bf343c5c6f4f4608faa48fc7521...   xsum   \n434  Claude-instant  592cfa0aa166f1c4ad4c35b913009774bddd8d65758421...   xsum   \n436     Google-PaLM  0b042bfd8735b78967638630404a5415dfd2ab9d1422df...   xsum   \n435     Llama-2-70b  1c3e99e696c1b014d3cc624638e95fe3789d2a57755499...   xsum   \n347         ChatGPT  96cdf9ce21e5202d5020711865821a860976c0e175ee6a...   xsum   \n351         ChatGPT  db019cdb3f2c58d0fbc4dc5026d2427a4f686af132cd00...   xsum   \n344  Claude-instant  b6c55736280df67cbf9e948ca514b508d79cafdf62f0db...   xsum   \n348  Claude-instant  b2bc9bb292a110b9296c558ef60845d23a844dc3eed769...   xsum   \n346     Google-PaLM  0b042bfd8735b78967638630404a5415dfd2ab9d1422df...   xsum   \n350     Google-PaLM  c9909605e35c21164f508d02da26267467ef61c8678bda...   xsum   \n345     Llama-2-70b  1c3e99e696c1b014d3cc624638e95fe3789d2a57755499...   xsum   \n349     Llama-2-70b  57339fd61e1817c2537b4bbeb3ca7fb26ac4596d8682ae...   xsum   \n414         ChatGPT  96cdf9ce21e5202d5020711865821a860976c0e175ee6a...   xsum   \n412  Claude-instant  592cfa0aa166f1c4ad4c35b913009774bddd8d65758421...   xsum   \n411     Google-PaLM  bb20bfe2a495d9368cde78161402dcab76b02ff62eace7...   xsum   \n413     Llama-2-70b  1c3e99e696c1b014d3cc624638e95fe3789d2a57755499...   xsum   \n387         ChatGPT  96cdf9ce21e5202d5020711865821a860976c0e175ee6a...   xsum   \n391         ChatGPT  db019cdb3f2c58d0fbc4dc5026d2427a4f686af132cd00...   xsum   \n385  Claude-instant  592cfa0aa166f1c4ad4c35b913009774bddd8d65758421...   xsum   \n389  Claude-instant  675e48e98da750aa34e5f8424577772f6223753cfc1a9b...   xsum   \n386     Google-PaLM  0b042bfd8735b78967638630404a5415dfd2ab9d1422df...   xsum   \n390     Google-PaLM  c9909605e35c21164f508d02da26267467ef61c8678bda...   xsum   \n384     Llama-2-70b  2c2a3bddcf9a2976b5335dfc36cebd032d59dacaa2f855...   xsum   \n388     Llama-2-70b  5ae50af7692a0d925ea14a6ea362ef4900151d7ca25d57...   xsum   \n\n     cleaned       llm_prompt  \n433     True  prompt_few_shot  \n434     True  prompt_few_shot  \n436     True  prompt_few_shot  \n435     True  prompt_few_shot  \n347     True  prompt_few_shot  \n351    False  prompt_few_shot  \n344     True  prompt_few_shot  \n348    False  prompt_few_shot  \n346     True  prompt_few_shot  \n350    False  prompt_few_shot  \n345     True  prompt_few_shot  \n349    False  prompt_few_shot  \n414     True  prompt_few_shot  \n412     True  prompt_few_shot  \n411     True  prompt_few_shot  \n413     True  prompt_few_shot  \n387     True  prompt_few_shot  \n391    False  prompt_few_shot  \n385     True  prompt_few_shot  \n389    False  prompt_few_shot  \n386     True  prompt_few_shot  \n390    False  prompt_few_shot  \n384     True  prompt_few_shot  \n388    False  prompt_few_shot  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>training_llm</th>\n      <th>test_llm</th>\n      <th>hash_df</th>\n      <th>domain</th>\n      <th>cleaned</th>\n      <th>llm_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>433</th>\n      <td>1.000000</td>\n      <td>-0.513668</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>ChatGPT</td>\n      <td>ChatGPT</td>\n      <td>ba91d0773ef08661745bf343c5c6f4f4608faa48fc7521...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>0.999926</td>\n      <td>-0.577739</td>\n      <td>[[698, 2], [1, 671]]</td>\n      <td>0.997028</td>\n      <td>0.998512</td>\n      <td>0.997770</td>\n      <td>0.997813</td>\n      <td>0.961310</td>\n      <td>ChatGPT</td>\n      <td>Claude-instant</td>\n      <td>592cfa0aa166f1c4ad4c35b913009774bddd8d65758421...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>0.922886</td>\n      <td>-0.660083</td>\n      <td>[[657, 43], [93, 455]]</td>\n      <td>0.913655</td>\n      <td>0.830292</td>\n      <td>0.869981</td>\n      <td>0.891026</td>\n      <td>0.549270</td>\n      <td>ChatGPT</td>\n      <td>Google-PaLM</td>\n      <td>0b042bfd8735b78967638630404a5415dfd2ab9d1422df...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>435</th>\n      <td>0.997618</td>\n      <td>-0.604820</td>\n      <td>[[689, 11], [10, 690]]</td>\n      <td>0.984308</td>\n      <td>0.985714</td>\n      <td>0.985011</td>\n      <td>0.985000</td>\n      <td>0.857143</td>\n      <td>ChatGPT</td>\n      <td>Llama-2-70b</td>\n      <td>1c3e99e696c1b014d3cc624638e95fe3789d2a57755499...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>0.998916</td>\n      <td>-0.663829</td>\n      <td>[[695, 5], [6, 694]]</td>\n      <td>0.992847</td>\n      <td>0.991429</td>\n      <td>0.992137</td>\n      <td>0.992143</td>\n      <td>0.614286</td>\n      <td>Claude-instant</td>\n      <td>ChatGPT</td>\n      <td>96cdf9ce21e5202d5020711865821a860976c0e175ee6a...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>0.999092</td>\n      <td>-0.619488</td>\n      <td>[[692, 8], [5, 695]]</td>\n      <td>0.988620</td>\n      <td>0.992857</td>\n      <td>0.990734</td>\n      <td>0.990714</td>\n      <td>0.607143</td>\n      <td>Claude-instant</td>\n      <td>ChatGPT</td>\n      <td>db019cdb3f2c58d0fbc4dc5026d2427a4f686af132cd00...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>1.000000</td>\n      <td>-0.537093</td>\n      <td>[[135, 0], [0, 140]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>b6c55736280df67cbf9e948ca514b508d79cafdf62f0db...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>1.000000</td>\n      <td>-0.518056</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>b2bc9bb292a110b9296c558ef60845d23a844dc3eed769...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>346</th>\n      <td>0.926449</td>\n      <td>-0.723472</td>\n      <td>[[670, 30], [86, 462]]</td>\n      <td>0.939024</td>\n      <td>0.843066</td>\n      <td>0.888462</td>\n      <td>0.907051</td>\n      <td>0.653285</td>\n      <td>Claude-instant</td>\n      <td>Google-PaLM</td>\n      <td>0b042bfd8735b78967638630404a5415dfd2ab9d1422df...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>0.930718</td>\n      <td>-0.670360</td>\n      <td>[[664, 36], [102, 598]]</td>\n      <td>0.943218</td>\n      <td>0.854286</td>\n      <td>0.896552</td>\n      <td>0.901429</td>\n      <td>0.674286</td>\n      <td>Claude-instant</td>\n      <td>Google-PaLM</td>\n      <td>c9909605e35c21164f508d02da26267467ef61c8678bda...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>0.996637</td>\n      <td>-0.678135</td>\n      <td>[[693, 7], [16, 684]]</td>\n      <td>0.989870</td>\n      <td>0.977143</td>\n      <td>0.983465</td>\n      <td>0.983571</td>\n      <td>0.931429</td>\n      <td>Claude-instant</td>\n      <td>Llama-2-70b</td>\n      <td>1c3e99e696c1b014d3cc624638e95fe3789d2a57755499...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>0.995820</td>\n      <td>-0.644321</td>\n      <td>[[687, 13], [12, 688]]</td>\n      <td>0.981455</td>\n      <td>0.982857</td>\n      <td>0.982156</td>\n      <td>0.982143</td>\n      <td>0.930000</td>\n      <td>Claude-instant</td>\n      <td>Llama-2-70b</td>\n      <td>57339fd61e1817c2537b4bbeb3ca7fb26ac4596d8682ae...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>0.999496</td>\n      <td>-0.554214</td>\n      <td>[[693, 7], [2, 698]]</td>\n      <td>0.990071</td>\n      <td>0.997143</td>\n      <td>0.993594</td>\n      <td>0.993571</td>\n      <td>0.841429</td>\n      <td>Google-PaLM</td>\n      <td>ChatGPT</td>\n      <td>96cdf9ce21e5202d5020711865821a860976c0e175ee6a...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>412</th>\n      <td>0.999977</td>\n      <td>-0.549740</td>\n      <td>[[699, 1], [2, 670]]</td>\n      <td>0.998510</td>\n      <td>0.997024</td>\n      <td>0.997766</td>\n      <td>0.997813</td>\n      <td>0.994048</td>\n      <td>Google-PaLM</td>\n      <td>Claude-instant</td>\n      <td>592cfa0aa166f1c4ad4c35b913009774bddd8d65758421...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>411</th>\n      <td>0.966380</td>\n      <td>-0.567474</td>\n      <td>[[146, 10], [8, 86]]</td>\n      <td>0.895833</td>\n      <td>0.914894</td>\n      <td>0.905263</td>\n      <td>0.928000</td>\n      <td>0.744681</td>\n      <td>Google-PaLM</td>\n      <td>Google-PaLM</td>\n      <td>bb20bfe2a495d9368cde78161402dcab76b02ff62eace7...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>0.996629</td>\n      <td>-0.554986</td>\n      <td>[[693, 7], [15, 685]]</td>\n      <td>0.989884</td>\n      <td>0.978571</td>\n      <td>0.984195</td>\n      <td>0.984286</td>\n      <td>0.964286</td>\n      <td>Google-PaLM</td>\n      <td>Llama-2-70b</td>\n      <td>1c3e99e696c1b014d3cc624638e95fe3789d2a57755499...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>387</th>\n      <td>0.999935</td>\n      <td>-0.636689</td>\n      <td>[[698, 2], [1, 699]]</td>\n      <td>0.997147</td>\n      <td>0.998571</td>\n      <td>0.997859</td>\n      <td>0.997857</td>\n      <td>0.962857</td>\n      <td>Llama-2-70b</td>\n      <td>ChatGPT</td>\n      <td>96cdf9ce21e5202d5020711865821a860976c0e175ee6a...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>0.999924</td>\n      <td>-0.645973</td>\n      <td>[[698, 2], [1, 699]]</td>\n      <td>0.997147</td>\n      <td>0.998571</td>\n      <td>0.997859</td>\n      <td>0.997857</td>\n      <td>0.961429</td>\n      <td>Llama-2-70b</td>\n      <td>ChatGPT</td>\n      <td>db019cdb3f2c58d0fbc4dc5026d2427a4f686af132cd00...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>385</th>\n      <td>1.000000</td>\n      <td>-0.647681</td>\n      <td>[[700, 0], [0, 672]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Llama-2-70b</td>\n      <td>Claude-instant</td>\n      <td>592cfa0aa166f1c4ad4c35b913009774bddd8d65758421...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>0.999982</td>\n      <td>-0.643186</td>\n      <td>[[700, 0], [1, 699]]</td>\n      <td>1.000000</td>\n      <td>0.998571</td>\n      <td>0.999285</td>\n      <td>0.999286</td>\n      <td>0.998571</td>\n      <td>Llama-2-70b</td>\n      <td>Claude-instant</td>\n      <td>675e48e98da750aa34e5f8424577772f6223753cfc1a9b...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>0.923973</td>\n      <td>-0.710997</td>\n      <td>[[668, 32], [90, 458]]</td>\n      <td>0.934694</td>\n      <td>0.835766</td>\n      <td>0.882466</td>\n      <td>0.902244</td>\n      <td>0.609489</td>\n      <td>Llama-2-70b</td>\n      <td>Google-PaLM</td>\n      <td>0b042bfd8735b78967638630404a5415dfd2ab9d1422df...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>0.937500</td>\n      <td>-0.725820</td>\n      <td>[[664, 36], [87, 613]]</td>\n      <td>0.944530</td>\n      <td>0.875714</td>\n      <td>0.908821</td>\n      <td>0.912143</td>\n      <td>0.687143</td>\n      <td>Llama-2-70b</td>\n      <td>Google-PaLM</td>\n      <td>c9909605e35c21164f508d02da26267467ef61c8678bda...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>384</th>\n      <td>0.996982</td>\n      <td>-0.670960</td>\n      <td>[[132, 1], [2, 145]]</td>\n      <td>0.993151</td>\n      <td>0.986395</td>\n      <td>0.989761</td>\n      <td>0.989286</td>\n      <td>0.952381</td>\n      <td>Llama-2-70b</td>\n      <td>Llama-2-70b</td>\n      <td>2c2a3bddcf9a2976b5335dfc36cebd032d59dacaa2f855...</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>0.996624</td>\n      <td>-0.679356</td>\n      <td>[[132, 1], [2, 145]]</td>\n      <td>0.993151</td>\n      <td>0.986395</td>\n      <td>0.989761</td>\n      <td>0.989286</td>\n      <td>0.952381</td>\n      <td>Llama-2-70b</td>\n      <td>Llama-2-70b</td>\n      <td>5ae50af7692a0d925ea14a6ea362ef4900151d7ca25d57...</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[(df_results[\"domain\"]==\"xsum\")&(df_results[\"llm_prompt\"]==\"prompt_few_shot\")].sort_values([\"training_llm\", \"test_llm\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:39:26.842490200Z",
     "start_time": "2025-06-27T06:39:26.366070700Z"
    }
   },
   "id": "74c4a01893e594fb"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "   cleaned   roc_auc  optimal_threshold  precision    recall        f1  \\\n0    False  0.990681          -0.515216   0.978927  0.973146  0.975622   \n1     True  0.989848          -0.527514   0.976161  0.971347  0.973392   \n\n   accuracy  tpr_at_fpr_0_01  \n0  0.976119         0.824088  \n1  0.975501         0.834621  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cleaned</th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>0.990681</td>\n      <td>-0.515216</td>\n      <td>0.978927</td>\n      <td>0.973146</td>\n      <td>0.975622</td>\n      <td>0.976119</td>\n      <td>0.824088</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0.989848</td>\n      <td>-0.527514</td>\n      <td>0.976161</td>\n      <td>0.971347</td>\n      <td>0.973392</td>\n      <td>0.975501</td>\n      <td>0.834621</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(\"cleaned\", as_index=False).mean(numeric_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:39:26.844491400Z",
     "start_time": "2025-06-27T06:39:26.464698500Z"
    }
   },
   "id": "a057f3e2cd7adadf"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "           domain   roc_auc  optimal_threshold  precision    recall        f1  \\\n0  writing_prompt  0.979544          -0.491796   0.948902  0.943296  0.945194   \n1            xsum  0.991576          -0.598557   0.985945  0.975025  0.980277   \n2           arxiv  0.999891          -0.494057   0.999496  0.998876  0.999184   \n\n   accuracy  tpr_at_fpr_0_01   cleaned  \n0  0.947664         0.608984  0.500000  \n1  0.982020         0.900628  0.661157  \n2  0.999185         0.997107  0.500000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>domain</th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>writing_prompt</td>\n      <td>0.979544</td>\n      <td>-0.491796</td>\n      <td>0.948902</td>\n      <td>0.943296</td>\n      <td>0.945194</td>\n      <td>0.947664</td>\n      <td>0.608984</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>xsum</td>\n      <td>0.991576</td>\n      <td>-0.598557</td>\n      <td>0.985945</td>\n      <td>0.975025</td>\n      <td>0.980277</td>\n      <td>0.982020</td>\n      <td>0.900628</td>\n      <td>0.661157</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>arxiv</td>\n      <td>0.999891</td>\n      <td>-0.494057</td>\n      <td>0.999496</td>\n      <td>0.998876</td>\n      <td>0.999184</td>\n      <td>0.999185</td>\n      <td>0.997107</td>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.groupby(\"domain\", as_index=False).mean(numeric_only=True).sort_values(by=\"roc_auc\").reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:54:59.035996900Z",
     "start_time": "2025-06-27T06:54:58.951950400Z"
    }
   },
   "id": "2e53df3471833bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   cleaned   roc_auc  optimal_threshold  precision    recall        f1  \\\n0    False  0.990523          -0.514943   0.980333  0.971965  0.975664   \n1     True  0.990286          -0.526181   0.978575  0.971389  0.974583   \n\n   accuracy  tpr_at_fpr_0_01  \n0  0.976393         0.845153  \n1  0.976715         0.850313  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cleaned</th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>0.990523</td>\n      <td>-0.514943</td>\n      <td>0.980333</td>\n      <td>0.971965</td>\n      <td>0.975664</td>\n      <td>0.976393</td>\n      <td>0.845153</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0.990286</td>\n      <td>-0.526181</td>\n      <td>0.978575</td>\n      <td>0.971389</td>\n      <td>0.974583</td>\n      <td>0.976715</td>\n      <td>0.850313</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_wo_human.groupby(\"cleaned\", as_index=False).mean(numeric_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:39:26.910023700Z",
     "start_time": "2025-06-27T06:39:26.503018Z"
    }
   },
   "id": "7b7e9b610c363d3c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "      roc_auc               conf_matrix  precision    recall        f1  \\\n273  0.749314   [[632, 68], [343, 340]]   0.833333  0.497804  0.623281   \n277  0.755400   [[635, 65], [347, 353]]   0.844498  0.504286  0.631485   \n317  0.863724   [[608, 92], [226, 474]]   0.837456  0.677143  0.748815   \n313  0.890398  [[598, 102], [170, 513]]   0.834146  0.751098  0.790447   \n233  0.898875   [[631, 69], [171, 512]]   0.881239  0.749634  0.810127   \n..        ...                       ...        ...       ...       ...   \n340  1.000000      [[133, 0], [0, 147]]   1.000000  1.000000  1.000000   \n344  1.000000      [[135, 0], [0, 140]]   1.000000  1.000000  1.000000   \n348  1.000000      [[133, 0], [0, 147]]   1.000000  1.000000  1.000000   \n352  1.000000      [[139, 0], [0, 136]]   1.000000  1.000000  1.000000   \n356  1.000000      [[133, 0], [0, 147]]   1.000000  1.000000  1.000000   \n\n     accuracy  tpr_at_fpr_0_01    training_llm        test_llm  \\\n273  0.702820         0.273792     Google-PaLM  Claude-instant   \n277  0.705714         0.277143     Google-PaLM  Claude-instant   \n317  0.772857         0.268571         ChatGPT  Claude-instant   \n313  0.803326         0.278184         ChatGPT  Claude-instant   \n233  0.826464         0.360176     Llama-2-70b  Claude-instant   \n..        ...              ...             ...             ...   \n340  1.000000         1.000000  Claude-instant  Claude-instant   \n344  1.000000         1.000000  Claude-instant  Claude-instant   \n348  1.000000         1.000000  Claude-instant  Claude-instant   \n352  1.000000         1.000000  Claude-instant  Claude-instant   \n356  1.000000         1.000000  Claude-instant  Claude-instant   \n\n             domain  cleaned             llm_prompt  \n273  writing_prompt     True            prompt_SICO  \n277  writing_prompt    False            prompt_SICO  \n317  writing_prompt    False            prompt_SICO  \n313  writing_prompt     True            prompt_SICO  \n233  writing_prompt     True            prompt_SICO  \n..              ...      ...                    ...  \n340            xsum    False  paraphrase_polish_llm  \n344            xsum     True        prompt_few_shot  \n348            xsum    False        prompt_few_shot  \n352            xsum     True            prompt_SICO  \n356            xsum    False            prompt_SICO  \n\n[88 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>training_llm</th>\n      <th>test_llm</th>\n      <th>domain</th>\n      <th>cleaned</th>\n      <th>llm_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>273</th>\n      <td>0.749314</td>\n      <td>[[632, 68], [343, 340]]</td>\n      <td>0.833333</td>\n      <td>0.497804</td>\n      <td>0.623281</td>\n      <td>0.702820</td>\n      <td>0.273792</td>\n      <td>Google-PaLM</td>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>0.755400</td>\n      <td>[[635, 65], [347, 353]]</td>\n      <td>0.844498</td>\n      <td>0.504286</td>\n      <td>0.631485</td>\n      <td>0.705714</td>\n      <td>0.277143</td>\n      <td>Google-PaLM</td>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>prompt_SICO</td>\n    </tr>\n    <tr>\n      <th>317</th>\n      <td>0.863724</td>\n      <td>[[608, 92], [226, 474]]</td>\n      <td>0.837456</td>\n      <td>0.677143</td>\n      <td>0.748815</td>\n      <td>0.772857</td>\n      <td>0.268571</td>\n      <td>ChatGPT</td>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>prompt_SICO</td>\n    </tr>\n    <tr>\n      <th>313</th>\n      <td>0.890398</td>\n      <td>[[598, 102], [170, 513]]</td>\n      <td>0.834146</td>\n      <td>0.751098</td>\n      <td>0.790447</td>\n      <td>0.803326</td>\n      <td>0.278184</td>\n      <td>ChatGPT</td>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n    </tr>\n    <tr>\n      <th>233</th>\n      <td>0.898875</td>\n      <td>[[631, 69], [171, 512]]</td>\n      <td>0.881239</td>\n      <td>0.749634</td>\n      <td>0.810127</td>\n      <td>0.826464</td>\n      <td>0.360176</td>\n      <td>Llama-2-70b</td>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>1.000000</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>1.000000</td>\n      <td>[[135, 0], [0, 140]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>1.000000</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>1.000000</td>\n      <td>[[139, 0], [0, 136]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>xsum</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>1.000000</td>\n      <td>[[133, 0], [0, 147]]</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>prompt_SICO</td>\n    </tr>\n  </tbody>\n</table>\n<p>88 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_wo_human[df_results_wo_human.test_llm==\"Claude-instant\"].sort_values(by=\"f1\").drop(columns=[\"hash_df\", 'optimal_threshold'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:39:27.141103600Z",
     "start_time": "2025-06-27T06:39:26.535791900Z"
    }
   },
   "id": "3009b33eceec61b1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "     training_llm   roc_auc  optimal_threshold  precision    recall        f1  \\\n0         ChatGPT  0.981837          -0.527498   0.965111  0.949738  0.956799   \n1  Claude-instant  0.992715          -0.513124   0.982632  0.981611  0.981882   \n2     Google-PaLM  0.965214          -0.531573   0.953049  0.922592  0.933388   \n3     Llama-2-70b  0.990267          -0.542659   0.980866  0.973065  0.976502   \n\n   accuracy  tpr_at_fpr_0_01  cleaned  \n0  0.959059         0.731664      0.6  \n1  0.981762         0.882144      0.5  \n2  0.941189         0.766582      0.6  \n3  0.977791         0.874352      0.5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>training_llm</th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ChatGPT</td>\n      <td>0.981837</td>\n      <td>-0.527498</td>\n      <td>0.965111</td>\n      <td>0.949738</td>\n      <td>0.956799</td>\n      <td>0.959059</td>\n      <td>0.731664</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Claude-instant</td>\n      <td>0.992715</td>\n      <td>-0.513124</td>\n      <td>0.982632</td>\n      <td>0.981611</td>\n      <td>0.981882</td>\n      <td>0.981762</td>\n      <td>0.882144</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Google-PaLM</td>\n      <td>0.965214</td>\n      <td>-0.531573</td>\n      <td>0.953049</td>\n      <td>0.922592</td>\n      <td>0.933388</td>\n      <td>0.941189</td>\n      <td>0.766582</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Llama-2-70b</td>\n      <td>0.990267</td>\n      <td>-0.542659</td>\n      <td>0.980866</td>\n      <td>0.973065</td>\n      <td>0.976502</td>\n      <td>0.977791</td>\n      <td>0.874352</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_wo_human[df_results_wo_human.test_llm==\"Claude-instant\"].groupby([\"training_llm\"], as_index=False).mean(numeric_only=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T06:39:27.176104100Z",
     "start_time": "2025-06-27T06:39:26.589343800Z"
    }
   },
   "id": "3a5f9d2001b28d15"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "      training_llm          domain  cleaned               llm_prompt  \\\n45  Claude-instant  writing_prompt     True              prompt_SICO   \n73     Google-PaLM  writing_prompt     True  paraphrase_polish_human   \n46  Claude-instant  writing_prompt     True          prompt_few_shot   \n68     Google-PaLM  writing_prompt    False  paraphrase_polish_human   \n38  Claude-instant  writing_prompt    False  paraphrase_polish_human   \n..             ...             ...      ...                      ...   \n59     Google-PaLM           arxiv    False    paraphrase_polish_llm   \n62     Google-PaLM           arxiv     True            direct_prompt   \n21         ChatGPT            xsum    False    paraphrase_polish_llm   \n8          ChatGPT           arxiv     True              prompt_SICO   \n20         ChatGPT            xsum    False  paraphrase_polish_human   \n\n     roc_auc  optimal_threshold  precision    recall        f1  accuracy  \\\n45  0.943680          -0.503004   0.884387  0.891900  0.887480  0.885770   \n73  0.966188          -0.541437   0.909680  0.921425  0.915198  0.922493   \n46  0.972884          -0.503488   0.902330  0.933553  0.917571  0.930323   \n68  0.970353          -0.516351   0.923675  0.928061  0.925093  0.923929   \n38  0.973160          -0.505484   0.914952  0.938639  0.926604  0.925000   \n..       ...                ...        ...       ...       ...       ...   \n59  0.999999          -0.493948   1.000000  0.999643  0.999821  0.999821   \n62  0.999999          -0.499061   1.000000  0.999643  0.999821  0.999821   \n21  1.000000          -0.393586   1.000000  1.000000  1.000000  1.000000   \n8   1.000000          -0.475486   1.000000  1.000000  1.000000  1.000000   \n20  1.000000          -0.502219   1.000000  1.000000  1.000000  1.000000   \n\n    tpr_at_fpr_0_01  \n45         0.207707  \n73         0.228651  \n46         0.247373  \n68         0.250085  \n38         0.290782  \n..              ...  \n59         0.999643  \n62         0.999643  \n21         1.000000  \n8          1.000000  \n20         1.000000  \n\n[113 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>training_llm</th>\n      <th>domain</th>\n      <th>cleaned</th>\n      <th>llm_prompt</th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n      <td>0.943680</td>\n      <td>-0.503004</td>\n      <td>0.884387</td>\n      <td>0.891900</td>\n      <td>0.887480</td>\n      <td>0.885770</td>\n      <td>0.207707</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>Google-PaLM</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>paraphrase_polish_human</td>\n      <td>0.966188</td>\n      <td>-0.541437</td>\n      <td>0.909680</td>\n      <td>0.921425</td>\n      <td>0.915198</td>\n      <td>0.922493</td>\n      <td>0.228651</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n      <td>0.972884</td>\n      <td>-0.503488</td>\n      <td>0.902330</td>\n      <td>0.933553</td>\n      <td>0.917571</td>\n      <td>0.930323</td>\n      <td>0.247373</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>Google-PaLM</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>paraphrase_polish_human</td>\n      <td>0.970353</td>\n      <td>-0.516351</td>\n      <td>0.923675</td>\n      <td>0.928061</td>\n      <td>0.925093</td>\n      <td>0.923929</td>\n      <td>0.250085</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>paraphrase_polish_human</td>\n      <td>0.973160</td>\n      <td>-0.505484</td>\n      <td>0.914952</td>\n      <td>0.938639</td>\n      <td>0.926604</td>\n      <td>0.925000</td>\n      <td>0.290782</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Google-PaLM</td>\n      <td>arxiv</td>\n      <td>False</td>\n      <td>paraphrase_polish_llm</td>\n      <td>0.999999</td>\n      <td>-0.493948</td>\n      <td>1.000000</td>\n      <td>0.999643</td>\n      <td>0.999821</td>\n      <td>0.999821</td>\n      <td>0.999643</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Google-PaLM</td>\n      <td>arxiv</td>\n      <td>True</td>\n      <td>direct_prompt</td>\n      <td>0.999999</td>\n      <td>-0.499061</td>\n      <td>1.000000</td>\n      <td>0.999643</td>\n      <td>0.999821</td>\n      <td>0.999821</td>\n      <td>0.999643</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ChatGPT</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>paraphrase_polish_llm</td>\n      <td>1.000000</td>\n      <td>-0.393586</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ChatGPT</td>\n      <td>arxiv</td>\n      <td>True</td>\n      <td>prompt_SICO</td>\n      <td>1.000000</td>\n      <td>-0.475486</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ChatGPT</td>\n      <td>xsum</td>\n      <td>False</td>\n      <td>paraphrase_polish_human</td>\n      <td>1.000000</td>\n      <td>-0.502219</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>113 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = (\n",
    "    df_results\n",
    "    .groupby([\"training_llm\", \"domain\", \"cleaned\", \"llm_prompt\"], as_index=False)\n",
    "    .mean(numeric_only=True)\n",
    ")\n",
    "\n",
    "grouped.sort_values(\"tpr_at_fpr_0_01\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T07:03:23.181340300Z",
     "start_time": "2025-06-27T07:03:23.053278500Z"
    }
   },
   "id": "86dc848e384256b0"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "cleaned\nTrue     240\nFalse    201\nName: count, dtype: int64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.cleaned.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T07:04:07.861464200Z",
     "start_time": "2025-06-27T07:04:07.772864200Z"
    }
   },
   "id": "673928b0479e32da"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "   cleaned   roc_auc  optimal_threshold  precision    recall        f1  \\\n0    False  0.990523          -0.514943   0.980333  0.971965  0.975664   \n1     True  0.990083          -0.515535   0.977874  0.971204  0.974100   \n\n   accuracy  tpr_at_fpr_0_01  \n0  0.976393         0.845153  \n1  0.976073         0.840754  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cleaned</th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>0.990523</td>\n      <td>-0.514943</td>\n      <td>0.980333</td>\n      <td>0.971965</td>\n      <td>0.975664</td>\n      <td>0.976393</td>\n      <td>0.845153</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0.990083</td>\n      <td>-0.515535</td>\n      <td>0.977874</td>\n      <td>0.971204</td>\n      <td>0.974100</td>\n      <td>0.976073</td>\n      <td>0.840754</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Group by the relevant columns and get unique values of \"cleaned\"\n",
    "COLUMNS = [\"training_llm\", \"domain\", \"llm_prompt\", \"test_llm\"]\n",
    "grouped = df_results_wo_human.groupby(COLUMNS)[\"cleaned\"].nunique()\n",
    "\n",
    "# Step 2: Keep only those groups where there are exactly 2 unique values (True and False)\n",
    "valid_combinations = grouped[grouped == 2].index\n",
    "\n",
    "# Step 3: Filter the original DataFrame\n",
    "filtered_df = df_results_wo_human[df_results_wo_human.set_index(COLUMNS).index.isin(valid_combinations)]\n",
    "filtered_df = filtered_df.reset_index(drop=True) \n",
    "filtered_df.groupby(\"cleaned\", as_index=False).mean(numeric_only=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T07:04:07.899464400Z",
     "start_time": "2025-06-27T07:04:07.789864300Z"
    }
   },
   "id": "4746952a8def95bf"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "cleaned    training_llm          domain             llm_prompt  \\\n0           Google-PaLM  writing_prompt        prompt_few_shot   \n1        Claude-instant  writing_prompt        prompt_few_shot   \n2        Claude-instant  writing_prompt            prompt_SICO   \n3        Claude-instant  writing_prompt        prompt_few_shot   \n4               ChatGPT  writing_prompt            prompt_SICO   \n..                  ...             ...                    ...   \n154         Llama-2-70b            xsum          direct_prompt   \n155         Llama-2-70b            xsum  paraphrase_polish_llm   \n156         Llama-2-70b            xsum  paraphrase_polish_llm   \n157         Llama-2-70b            xsum        prompt_few_shot   \n158         Llama-2-70b            xsum        prompt_few_shot   \n\ncleaned        test_llm      diff  abs_diff  \n0           Google-PaLM -0.069101  0.069101  \n1           Google-PaLM -0.068263  0.068263  \n2        Claude-instant -0.065995  0.065995  \n3        Claude-instant -0.058813  0.058813  \n4        Claude-instant  0.041632  0.041632  \n..                  ...       ...       ...  \n154             ChatGPT  0.000000  0.000000  \n155             ChatGPT  0.000000  0.000000  \n156         Llama-2-70b  0.000000  0.000000  \n157             ChatGPT  0.000000  0.000000  \n158         Llama-2-70b  0.000000  0.000000  \n\n[159 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cleaned</th>\n      <th>training_llm</th>\n      <th>domain</th>\n      <th>llm_prompt</th>\n      <th>test_llm</th>\n      <th>diff</th>\n      <th>abs_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Google-PaLM</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Google-PaLM</td>\n      <td>-0.069101</td>\n      <td>0.069101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Google-PaLM</td>\n      <td>-0.068263</td>\n      <td>0.068263</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>prompt_SICO</td>\n      <td>Claude-instant</td>\n      <td>-0.065995</td>\n      <td>0.065995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Claude-instant</td>\n      <td>-0.058813</td>\n      <td>0.058813</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ChatGPT</td>\n      <td>writing_prompt</td>\n      <td>prompt_SICO</td>\n      <td>Claude-instant</td>\n      <td>0.041632</td>\n      <td>0.041632</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>Llama-2-70b</td>\n      <td>xsum</td>\n      <td>direct_prompt</td>\n      <td>ChatGPT</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>Llama-2-70b</td>\n      <td>xsum</td>\n      <td>paraphrase_polish_llm</td>\n      <td>ChatGPT</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>Llama-2-70b</td>\n      <td>xsum</td>\n      <td>paraphrase_polish_llm</td>\n      <td>Llama-2-70b</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>Llama-2-70b</td>\n      <td>xsum</td>\n      <td>prompt_few_shot</td>\n      <td>ChatGPT</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>Llama-2-70b</td>\n      <td>xsum</td>\n      <td>prompt_few_shot</td>\n      <td>Llama-2-70b</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>159 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Pivot so that we get f1 values for cleaned == True and False side-by-side\n",
    "pivoted = (\n",
    "    filtered_df.pivot_table(\n",
    "        index=COLUMNS,\n",
    "        columns=\"cleaned\",\n",
    "        values=\"f1\"\n",
    "    )\n",
    "    .dropna()  # Drop any rows with missing data just in case\n",
    ")\n",
    "\n",
    "# Step 3: Compute the difference\n",
    "pivoted[\"diff\"] = pivoted[True] - pivoted[False]\n",
    "pivoted[\"abs_diff\"] = pivoted[\"diff\"].abs()\n",
    "\n",
    "# Step 4: Show top 10 combinations with the highest absolute difference\n",
    "top10 = pivoted.sort_values(\"abs_diff\", ascending=False)\n",
    "\n",
    "# Optional: clean up the display\n",
    "top10_display = top10[[\"diff\", \"abs_diff\"]].reset_index()\n",
    "# top10_display.head(10)\n",
    "top10_display"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T07:07:08.830633600Z",
     "start_time": "2025-06-27T07:07:08.767976300Z"
    }
   },
   "id": "17f6140d2273f971"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "cleaned    training_llm          domain       llm_prompt        test_llm  \\\n0           Google-PaLM  writing_prompt  prompt_few_shot     Google-PaLM   \n1        Claude-instant  writing_prompt  prompt_few_shot     Google-PaLM   \n2        Claude-instant  writing_prompt      prompt_SICO  Claude-instant   \n3        Claude-instant  writing_prompt  prompt_few_shot  Claude-instant   \n4               ChatGPT  writing_prompt      prompt_SICO  Claude-instant   \n5           Llama-2-70b            xsum  prompt_few_shot     Google-PaLM   \n6           Google-PaLM  writing_prompt  prompt_few_shot     Llama-2-70b   \n7        Claude-instant  writing_prompt      prompt_SICO     Llama-2-70b   \n8           Llama-2-70b  writing_prompt  prompt_few_shot     Google-PaLM   \n9               ChatGPT  writing_prompt  prompt_few_shot     Google-PaLM   \n\ncleaned      diff  abs_diff  \n0       -0.069101  0.069101  \n1       -0.068263  0.068263  \n2       -0.065995  0.065995  \n3       -0.058813  0.058813  \n4        0.041632  0.041632  \n5       -0.026355  0.026355  \n6        0.021409  0.021409  \n7       -0.019831  0.019831  \n8       -0.019075  0.019075  \n9       -0.018670  0.018670  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>cleaned</th>\n      <th>training_llm</th>\n      <th>domain</th>\n      <th>llm_prompt</th>\n      <th>test_llm</th>\n      <th>diff</th>\n      <th>abs_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Google-PaLM</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Google-PaLM</td>\n      <td>-0.069101</td>\n      <td>0.069101</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Google-PaLM</td>\n      <td>-0.068263</td>\n      <td>0.068263</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>prompt_SICO</td>\n      <td>Claude-instant</td>\n      <td>-0.065995</td>\n      <td>0.065995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Claude-instant</td>\n      <td>-0.058813</td>\n      <td>0.058813</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ChatGPT</td>\n      <td>writing_prompt</td>\n      <td>prompt_SICO</td>\n      <td>Claude-instant</td>\n      <td>0.041632</td>\n      <td>0.041632</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Llama-2-70b</td>\n      <td>xsum</td>\n      <td>prompt_few_shot</td>\n      <td>Google-PaLM</td>\n      <td>-0.026355</td>\n      <td>0.026355</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Google-PaLM</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Llama-2-70b</td>\n      <td>0.021409</td>\n      <td>0.021409</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Claude-instant</td>\n      <td>writing_prompt</td>\n      <td>prompt_SICO</td>\n      <td>Llama-2-70b</td>\n      <td>-0.019831</td>\n      <td>0.019831</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Llama-2-70b</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Google-PaLM</td>\n      <td>-0.019075</td>\n      <td>0.019075</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ChatGPT</td>\n      <td>writing_prompt</td>\n      <td>prompt_few_shot</td>\n      <td>Google-PaLM</td>\n      <td>-0.018670</td>\n      <td>0.018670</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_display.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T07:07:54.216535300Z",
     "start_time": "2025-06-27T07:07:54.094421Z"
    }
   },
   "id": "6bd7365793ae969a"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "      roc_auc  optimal_threshold             conf_matrix  precision    recall  \\\n184  0.979957          -0.505787   [[144, 13], [5, 104]]   0.888889  0.954128   \n185  0.940752          -0.510063  [[612, 88], [73, 626]]   0.876751  0.895565   \n186  0.977923          -0.498682  [[665, 35], [29, 275]]   0.887097  0.904605   \n187  0.992902          -0.499420  [[669, 31], [14, 683]]   0.956583  0.979914   \n188  0.996368          -0.485927    [[133, 0], [6, 141]]   1.000000  0.959184   \n189  0.952296          -0.502553  [[633, 67], [88, 612]]   0.901325  0.874286   \n190  0.983965          -0.492166  [[680, 20], [30, 670]]   0.971014  0.957143   \n191  0.995420          -0.490298  [[688, 12], [24, 676]]   0.982558  0.965714   \n\n           f1  accuracy  tpr_at_fpr_0_01    training_llm        test_llm  \\\n184  0.920354  0.932331         0.275229  Claude-instant  Claude-instant   \n185  0.886058  0.884918         0.032904  Claude-instant     Llama-2-70b   \n186  0.895765  0.936255         0.223684  Claude-instant     Google-PaLM   \n187  0.968108  0.967788         0.457676  Claude-instant         ChatGPT   \n188  0.979167  0.978571         0.959184  Claude-instant  Claude-instant   \n189  0.887600  0.889286         0.090000  Claude-instant     Llama-2-70b   \n190  0.964029  0.964286         0.185714  Claude-instant     Google-PaLM   \n191  0.974063  0.974286         0.432857  Claude-instant         ChatGPT   \n\n                                               hash_df          domain  \\\n184  890386674417d8ddb48f96dea27e383b92165c3db6c5dc...  writing_prompt   \n185  44f3aae5e8f0f3cee831bb0714df8c95063d650f1677e9...  writing_prompt   \n186  fa3295986d18c71b05ac05e549c573a6c89a55d207c419...  writing_prompt   \n187  2b91a125f0c7f39f4bee5cdb90e5a5cbe91cd76e8a02ab...  writing_prompt   \n188  8262be56c5018c8817ad61af58ab724ecc543452a919be...  writing_prompt   \n189  f9babf5b1bbfc0b7816bf9778fcf43586c41c87780c52e...  writing_prompt   \n190  6cda2362c15d7011036d4a166b347abb6ba17192a87a49...  writing_prompt   \n191  228f44b376166a75b25d94ddc61c71e6aacb44869ca9dc...  writing_prompt   \n\n     cleaned       llm_prompt  \n184     True  prompt_few_shot  \n185     True  prompt_few_shot  \n186     True  prompt_few_shot  \n187     True  prompt_few_shot  \n188    False  prompt_few_shot  \n189    False  prompt_few_shot  \n190    False  prompt_few_shot  \n191    False  prompt_few_shot  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>training_llm</th>\n      <th>test_llm</th>\n      <th>hash_df</th>\n      <th>domain</th>\n      <th>cleaned</th>\n      <th>llm_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>184</th>\n      <td>0.979957</td>\n      <td>-0.505787</td>\n      <td>[[144, 13], [5, 104]]</td>\n      <td>0.888889</td>\n      <td>0.954128</td>\n      <td>0.920354</td>\n      <td>0.932331</td>\n      <td>0.275229</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>890386674417d8ddb48f96dea27e383b92165c3db6c5dc...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>0.940752</td>\n      <td>-0.510063</td>\n      <td>[[612, 88], [73, 626]]</td>\n      <td>0.876751</td>\n      <td>0.895565</td>\n      <td>0.886058</td>\n      <td>0.884918</td>\n      <td>0.032904</td>\n      <td>Claude-instant</td>\n      <td>Llama-2-70b</td>\n      <td>44f3aae5e8f0f3cee831bb0714df8c95063d650f1677e9...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>0.977923</td>\n      <td>-0.498682</td>\n      <td>[[665, 35], [29, 275]]</td>\n      <td>0.887097</td>\n      <td>0.904605</td>\n      <td>0.895765</td>\n      <td>0.936255</td>\n      <td>0.223684</td>\n      <td>Claude-instant</td>\n      <td>Google-PaLM</td>\n      <td>fa3295986d18c71b05ac05e549c573a6c89a55d207c419...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>0.992902</td>\n      <td>-0.499420</td>\n      <td>[[669, 31], [14, 683]]</td>\n      <td>0.956583</td>\n      <td>0.979914</td>\n      <td>0.968108</td>\n      <td>0.967788</td>\n      <td>0.457676</td>\n      <td>Claude-instant</td>\n      <td>ChatGPT</td>\n      <td>2b91a125f0c7f39f4bee5cdb90e5a5cbe91cd76e8a02ab...</td>\n      <td>writing_prompt</td>\n      <td>True</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>0.996368</td>\n      <td>-0.485927</td>\n      <td>[[133, 0], [6, 141]]</td>\n      <td>1.000000</td>\n      <td>0.959184</td>\n      <td>0.979167</td>\n      <td>0.978571</td>\n      <td>0.959184</td>\n      <td>Claude-instant</td>\n      <td>Claude-instant</td>\n      <td>8262be56c5018c8817ad61af58ab724ecc543452a919be...</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>0.952296</td>\n      <td>-0.502553</td>\n      <td>[[633, 67], [88, 612]]</td>\n      <td>0.901325</td>\n      <td>0.874286</td>\n      <td>0.887600</td>\n      <td>0.889286</td>\n      <td>0.090000</td>\n      <td>Claude-instant</td>\n      <td>Llama-2-70b</td>\n      <td>f9babf5b1bbfc0b7816bf9778fcf43586c41c87780c52e...</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>0.983965</td>\n      <td>-0.492166</td>\n      <td>[[680, 20], [30, 670]]</td>\n      <td>0.971014</td>\n      <td>0.957143</td>\n      <td>0.964029</td>\n      <td>0.964286</td>\n      <td>0.185714</td>\n      <td>Claude-instant</td>\n      <td>Google-PaLM</td>\n      <td>6cda2362c15d7011036d4a166b347abb6ba17192a87a49...</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>0.995420</td>\n      <td>-0.490298</td>\n      <td>[[688, 12], [24, 676]]</td>\n      <td>0.982558</td>\n      <td>0.965714</td>\n      <td>0.974063</td>\n      <td>0.974286</td>\n      <td>0.432857</td>\n      <td>Claude-instant</td>\n      <td>ChatGPT</td>\n      <td>228f44b376166a75b25d94ddc61c71e6aacb44869ca9dc...</td>\n      <td>writing_prompt</td>\n      <td>False</td>\n      <td>prompt_few_shot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_wo_human[(df_results_wo_human[\"training_llm\"]==\"Claude-instant\")&(df_results_wo_human[\"domain\"]==\"writing_prompt\")&(df_results_wo_human[\"llm_prompt\"]==\"prompt_few_shot\")]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-27T07:04:08.027042800Z",
     "start_time": "2025-06-27T07:04:07.932511700Z"
    }
   },
   "id": "dfbb9cfd0223259c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
