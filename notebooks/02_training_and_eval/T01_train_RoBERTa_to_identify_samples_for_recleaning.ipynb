{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "319f65fe11f6c526"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0.0 imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e68036cf48b465df"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-11T10:34:35.903989500Z",
     "start_time": "2025-09-11T10:34:35.888846600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Literal\n",
    "\n",
    "BASE_DIR = \"../../\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "from src.general_functions_and_patterns_for_detection import (\n",
    "    TrainRobertaHelper, TrainingDataHandler,\n",
    "    RESULT_DIR, REGEX_CLEANED_FILES, ORIGINAL_DATA_DIR,\n",
    "    seed_everything\n",
    ")\n",
    "\n",
    "SEED = 2023\n",
    "seed_everything(SEED)\n",
    "\n",
    "prepare_df_for_roberta_training = TrainRobertaHelper.prepare_df_for_roberta_training\n",
    "import DetectRL.Detectors.train_roberta as train_roberta\n",
    "\n",
    "DEBUG = True\n",
    "DRY_RUN = False\n",
    "ALL_DATA = True\n",
    "RESULT_DIR = os.path.join(RESULT_DIR, \"T01\")\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# TODO: adjust CUDA setup depending on your setup\n",
    "# Disable NCCL features incompatible with RTX 40xx\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\"\n",
    "\n",
    "# Restrict to only GPU 0 (CUDA:0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T09:30:34.509089100Z",
     "start_time": "2025-09-11T09:30:34.505026300Z"
    }
   },
   "id": "a6956259b0419b39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Train multi LLM across all domains\n",
    "\n",
    "- check which data is worth to be recleaned --> typical pattern for each LLM individually that are present across multiple domains\n",
    "- selection made based on the data, that is most likely AI generated on an uncleaned model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4725b407b734745"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# PROMPTS=[\"direct_prompt\", \"prompt_few_shot\", \"prompt_SICO\"]\n",
    "PROMPTS=[\"paraphrase_polish_human\", \"paraphrase_polish_llm\"]\n",
    "_prompt_str = \"_\" + \"-\".join(PROMPTS)\n",
    "\n",
    "df_claude_cleaned, df_llama_cleaned, df_palm_cleaned, df_chatgpt_cleaned = \\\n",
    "    TrainingDataHandler.load_dataframes_all_llms_all_domains(REGEX_CLEANED_FILES, _suffix_path=\"_cleaned_all_v3.parquet\", prompts=PROMPTS, paraphrase_polish_human_as_ai=False)\n",
    "\n",
    "cleaned_df: dict = {\n",
    "    \"claude\": df_claude_cleaned, \"llama\": df_llama_cleaned, \n",
    "    \"palm\": df_palm_cleaned, \"chatgpt\": df_chatgpt_cleaned\n",
    "}\n",
    "\n",
    "df_claude_nc, df_llama_nc, df_palm_nc, df_chatgpt_nc = \\\n",
    "    TrainingDataHandler.load_dataframes_all_llms_all_domains(ORIGINAL_DATA_DIR, _suffix_path=\".json\", prompts=PROMPTS, paraphrase_polish_human_as_ai=False)\n",
    "\n",
    "uncleaned_df: dict = {\n",
    "    \"claude\": df_claude_nc, \"llama\": df_llama_nc, \n",
    "    \"palm\": df_palm_nc, \"chatgpt\": df_chatgpt_nc\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T09:30:38.468358300Z",
     "start_time": "2025-09-11T09:30:34.513124100Z"
    }
   },
   "id": "524311468a6a9ddf"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# evaluate\n",
    "# train using the cleaned domains and training structures\n",
    "train_df_claude, test_df_claude, adjusted_df_claude, sample_ids_claude = \\\n",
    "    TrainingDataHandler.split_training_data_frame_and_adjust_transfer_test_df(df_claude_cleaned, df_claude_nc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T09:30:38.479651Z",
     "start_time": "2025-09-11T09:30:38.468358300Z"
    }
   },
   "id": "f548513e94e226ef"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def modify_and_store_df(_df_results: pd.DataFrame, _llm_training: str, _transfer_df_dict: dict = None, _dfs_used_for_testing: list = None,\n",
    "                        samples: Literal[\"cleaned\", \"original\"] = \"original\"):\n",
    "    _df_results = pd.DataFrame(_df_results).T\n",
    "    if _dfs_used_for_testing is not None:\n",
    "        _df_results[\"df_used_for_testing\"] = _dfs_used_for_testing    \n",
    "    elif _transfer_df_dict is not None:\n",
    "        _df_results[\"df_used_for_testing\"] = _transfer_df_dict.keys()\n",
    "    else:\n",
    "        raise ValueError(\"Either dict with transfer dataframes or list with dataframe names used for testing has to be provided\")\n",
    "    _df_results[\"domain_test\"] = [PROMPTS for _ in range(len(_df_results))]\n",
    "    _df_results[\"cleaned\"] = _df_results[\"df_used_for_testing\"].apply(lambda x: \"nc\" not in x)\n",
    "    _df_results.to_csv(f\"{RESULT_DIR}/{_llm_training}_trained_{samples}_samples_results{_prompt_str}.csv\")\n",
    "    return _df_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T12:35:03.032620100Z",
     "start_time": "2025-09-11T12:35:02.997034600Z"
    }
   },
   "id": "a72bfb3b35b69122"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3076507f7cfdba0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Using cleaned data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a55e2ba269305f8b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11186, 7) (10647, 7) (11197, 7)\n",
      "(11200, 7) (11200, 7) (11200, 7)\n",
      "(2240, 7) (2211, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": "         id                                            context  \\\n11177  2078  Barnes & Noble in Southpark is a great place t...   \n11183  2084  So help me God, if I ever get married or have ...   \n11184  2085  I drive out here for these reasons: nnI like m...   \n11186  2087  While in Charlotte for business we ventured to...   \n11193  2094                       Oh upstream how I love thee.   \n\n             llm_type                                               text  \\\n11177  Claude-instant  Here is a polished 17 sentence continuation of...   \n11183  Claude-instant  Here is a polished version of the review with ...   \n11184  Claude-instant  Here is my attempt at polishing the review whi...   \n11186  Claude-instant  Here is a polished 14 sentence review:During o...   \n11193  Claude-instant  Here is my attempt at polishing the review whi...   \n\n            domain label llm_prompting_strategy  \n11177  yelp_review   llm  paraphrase_polish_llm  \n11183  yelp_review   llm  paraphrase_polish_llm  \n11184  yelp_review   llm  paraphrase_polish_llm  \n11186  yelp_review   llm  paraphrase_polish_llm  \n11193  yelp_review   llm  paraphrase_polish_llm  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>context</th>\n      <th>llm_type</th>\n      <th>text</th>\n      <th>domain</th>\n      <th>label</th>\n      <th>llm_prompting_strategy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11177</th>\n      <td>2078</td>\n      <td>Barnes &amp; Noble in Southpark is a great place t...</td>\n      <td>Claude-instant</td>\n      <td>Here is a polished 17 sentence continuation of...</td>\n      <td>yelp_review</td>\n      <td>llm</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>11183</th>\n      <td>2084</td>\n      <td>So help me God, if I ever get married or have ...</td>\n      <td>Claude-instant</td>\n      <td>Here is a polished version of the review with ...</td>\n      <td>yelp_review</td>\n      <td>llm</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>11184</th>\n      <td>2085</td>\n      <td>I drive out here for these reasons: nnI like m...</td>\n      <td>Claude-instant</td>\n      <td>Here is my attempt at polishing the review whi...</td>\n      <td>yelp_review</td>\n      <td>llm</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>11186</th>\n      <td>2087</td>\n      <td>While in Charlotte for business we ventured to...</td>\n      <td>Claude-instant</td>\n      <td>Here is a polished 14 sentence review:During o...</td>\n      <td>yelp_review</td>\n      <td>llm</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n    <tr>\n      <th>11193</th>\n      <td>2094</td>\n      <td>Oh upstream how I love thee.</td>\n      <td>Claude-instant</td>\n      <td>Here is my attempt at polishing the review whi...</td>\n      <td>yelp_review</td>\n      <td>llm</td>\n      <td>paraphrase_polish_llm</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_llama_cleaned.shape, df_palm_cleaned.shape, df_chatgpt_cleaned.shape)\n",
    "print(df_llama_nc.shape, df_palm_nc.shape, df_chatgpt_nc.shape)\n",
    "print(adjusted_df_claude.shape, test_df_claude.shape)\n",
    "adjusted_df_claude.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T09:30:38.514758500Z",
     "start_time": "2025-09-11T09:30:38.510504100Z"
    }
   },
   "id": "5c17feba70601ac2"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     roc_auc  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.956643   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.948450   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.945368   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.975582   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.961399   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.944598   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.930352   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.975549   \n\n                                                    optimal_threshold  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...          -0.754963   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...          -0.974335   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...          -0.994146   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...          -0.176101   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...          -0.966674   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...          -0.984199   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...          -0.994870   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          -0.176101   \n\n                                                                    conf_matrix  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     [[1452, 207], [29, 523]]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  [[7260, 1136], [288, 2502]]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  [[6601, 1377], [167, 2502]]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...    [[7829, 568], [64, 2736]]   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...     [[1465, 215], [32, 528]]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  [[7108, 1292], [271, 2529]]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  [[6655, 1745], [183, 2617]]   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    [[7834, 566], [66, 2734]]   \n\n                                                    precision    recall  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...   0.716438  0.947464   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...   0.687741  0.896774   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...   0.645012  0.937430   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...   0.828087  0.977143   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...   0.710633  0.942857   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...   0.661869  0.903214   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...   0.599954  0.934643   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...   0.828485  0.976429   \n\n                                                          f1  accuracy  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.815913  0.893261   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.778469  0.872698   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.764203  0.854983   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.896461  0.943556   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.810437  0.889732   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.763933  0.860446   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.730801  0.827857   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.896393  0.943571   \n\n                                                    tpr_at_fpr_0_01  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...         0.001812   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...         0.000717   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...         0.001124   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         0.003214   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...         0.025000   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...         0.000714   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...         0.000357   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         0.003214   \n\n                                                   df_used_for_testing  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...      claude_cleaned   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...       llama_cleaned   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...        palm_cleaned   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     chatgpt_cleaned   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...           claude_nc   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...            llama_nc   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...             palm_nc   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          chatgpt_nc   \n\n                                                                                          domain_test  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  ['paraphrase_polish_human', 'paraphrase_polish...   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  ['paraphrase_polish_human', 'paraphrase_polish...   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  ['paraphrase_polish_human', 'paraphrase_polish...   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  ['paraphrase_polish_human', 'paraphrase_polish...   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  ['paraphrase_polish_human', 'paraphrase_polish...   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  ['paraphrase_polish_human', 'paraphrase_polish...   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  ['paraphrase_polish_human', 'paraphrase_polish...   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  ['paraphrase_polish_human', 'paraphrase_polish...   \n\n                                                    cleaned  \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     True  \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     True  \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     True  \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     True  \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...    False  \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...    False  \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...    False  \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>df_used_for_testing</th>\n      <th>domain_test</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50ba7b748eacd56133c2_train</th>\n      <td>0.956643</td>\n      <td>-0.754963</td>\n      <td>[[1452, 207], [29, 523]]</td>\n      <td>0.716438</td>\n      <td>0.947464</td>\n      <td>0.815913</td>\n      <td>0.893261</td>\n      <td>0.001812</td>\n      <td>claude_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536f7e5cedc7762c67b8_train</th>\n      <td>0.948450</td>\n      <td>-0.974335</td>\n      <td>[[7260, 1136], [288, 2502]]</td>\n      <td>0.687741</td>\n      <td>0.896774</td>\n      <td>0.778469</td>\n      <td>0.872698</td>\n      <td>0.000717</td>\n      <td>llama_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da772338248b91727fa_train</th>\n      <td>0.945368</td>\n      <td>-0.994146</td>\n      <td>[[6601, 1377], [167, 2502]]</td>\n      <td>0.645012</td>\n      <td>0.937430</td>\n      <td>0.764203</td>\n      <td>0.854983</td>\n      <td>0.001124</td>\n      <td>palm_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e92716642bed23d09fb55bad_train</th>\n      <td>0.975582</td>\n      <td>-0.176101</td>\n      <td>[[7829, 568], [64, 2736]]</td>\n      <td>0.828087</td>\n      <td>0.977143</td>\n      <td>0.896461</td>\n      <td>0.943556</td>\n      <td>0.003214</td>\n      <td>chatgpt_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc074172ca5a88577c0d5db7_train</th>\n      <td>0.961399</td>\n      <td>-0.966674</td>\n      <td>[[1465, 215], [32, 528]]</td>\n      <td>0.710633</td>\n      <td>0.942857</td>\n      <td>0.810437</td>\n      <td>0.889732</td>\n      <td>0.025000</td>\n      <td>claude_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>357d2f75d787f00787f2bfb31c367978d56fe2843e11ae420e2a3ccc538ad93e_train</th>\n      <td>0.944598</td>\n      <td>-0.984199</td>\n      <td>[[7108, 1292], [271, 2529]]</td>\n      <td>0.661869</td>\n      <td>0.903214</td>\n      <td>0.763933</td>\n      <td>0.860446</td>\n      <td>0.000714</td>\n      <td>llama_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>277d294ec1bf7b980608af53a29c176de2de7c1ffd062c77f36eabc843565065_train</th>\n      <td>0.930352</td>\n      <td>-0.994870</td>\n      <td>[[6655, 1745], [183, 2617]]</td>\n      <td>0.599954</td>\n      <td>0.934643</td>\n      <td>0.730801</td>\n      <td>0.827857</td>\n      <td>0.000357</td>\n      <td>palm_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>a617f5d6441618fcb86810cddd0538c3b18dd27901b0be621495d69be376d7c4_train</th>\n      <td>0.975549</td>\n      <td>-0.176101</td>\n      <td>[[7834, 566], [66, 2734]]</td>\n      <td>0.828485</td>\n      <td>0.976429</td>\n      <td>0.896393</td>\n      <td>0.943571</td>\n      <td>0.003214</td>\n      <td>chatgpt_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = train_roberta.generate_args_for_training_roberta(\n",
    "    train_df = train_df_claude, test_df = test_df_claude, transfer_df=[test_df_claude, df_llama_cleaned, df_palm_cleaned, df_chatgpt_cleaned, \n",
    "                                                                       adjusted_df_claude, df_llama_nc, df_palm_nc, df_chatgpt_nc],\n",
    "    save_model_path=f\"{RESULT_DIR}claude_direct_prompt_all_domains_multi_llm_cleaned{_prompt_str}\"\n",
    ")\n",
    "results_cleaned_train = train_roberta.run(args)\n",
    "df_cleaned_train = modify_and_store_df(results_cleaned_train, \"claude\", \n",
    "                                       _dfs_used_for_testing= [\"claude_cleaned\", \"llama_cleaned\", \"palm_cleaned\", \"chatgpt_cleaned\", \n",
    "                                                              \"claude_nc\", \"llama_nc\", \"palm_nc\", \"chatgpt_nc\"],\n",
    "                                       samples=\"cleaned\")\n",
    "df_cleaned_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T10:36:58.663341400Z",
     "start_time": "2025-09-11T10:36:58.605909800Z"
    }
   },
   "id": "27100dba08bf175c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Using original data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa5b86d788074040"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Claude"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f060b79273fadb87"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     roc_auc  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.960867   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.946975   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.941164   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.983951   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.961763   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.946071   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.931743   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.983967   \n\n                                                    optimal_threshold  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...          -0.940477   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...          -0.967297   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...          -0.994278   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...          -0.136667   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...          -0.928909   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...          -0.967330   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...          -0.995067   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          -0.136667   \n\n                                                                    conf_matrix  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     [[1406, 253], [20, 532]]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  [[7281, 1115], [344, 2446]]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  [[6597, 1381], [220, 2449]]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...    [[7794, 603], [84, 2716]]   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...     [[1421, 259], [22, 538]]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  [[7289, 1111], [351, 2449]]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  [[6563, 1837], [206, 2594]]   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    [[7798, 602], [83, 2717]]   \n\n                                                    precision    recall  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...   0.677707  0.963768   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...   0.686886  0.876703   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...   0.639426  0.917572   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...   0.818319  0.970000   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...   0.675031  0.960714   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...   0.687921  0.874643   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...   0.585421  0.926429   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...   0.818620  0.970357   \n\n                                                          f1  accuracy  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.795812  0.876526   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.770272  0.869569   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.753654  0.849629   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.887727  0.938644   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.792926  0.874554   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.770126  0.869464   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.717466  0.817589   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.888054  0.938839   \n\n                                                    tpr_at_fpr_0_01  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...         0.021739   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...         0.001434   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...         0.030723   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         0.007500   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...         0.025000   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...         0.001429   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...         0.030357   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         0.007857   \n\n                                                   df_used_for_testing  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...      claude_cleaned   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...       llama_cleaned   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...        palm_cleaned   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     chatgpt_cleaned   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...           claude_nc   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...            llama_nc   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...             palm_nc   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          chatgpt_nc   \n\n                                                                                          domain_test  \\\nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  ['paraphrase_polish_human', 'paraphrase_polish...   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  ['paraphrase_polish_human', 'paraphrase_polish...   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  ['paraphrase_polish_human', 'paraphrase_polish...   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  ['paraphrase_polish_human', 'paraphrase_polish...   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  ['paraphrase_polish_human', 'paraphrase_polish...   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  ['paraphrase_polish_human', 'paraphrase_polish...   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  ['paraphrase_polish_human', 'paraphrase_polish...   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  ['paraphrase_polish_human', 'paraphrase_polish...   \n\n                                                    cleaned  \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     True  \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     True  \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     True  \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     True  \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...    False  \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...    False  \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...    False  \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>df_used_for_testing</th>\n      <th>domain_test</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50ba7b748eacd56133c2_train</th>\n      <td>0.960867</td>\n      <td>-0.940477</td>\n      <td>[[1406, 253], [20, 532]]</td>\n      <td>0.677707</td>\n      <td>0.963768</td>\n      <td>0.795812</td>\n      <td>0.876526</td>\n      <td>0.021739</td>\n      <td>claude_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536f7e5cedc7762c67b8_train</th>\n      <td>0.946975</td>\n      <td>-0.967297</td>\n      <td>[[7281, 1115], [344, 2446]]</td>\n      <td>0.686886</td>\n      <td>0.876703</td>\n      <td>0.770272</td>\n      <td>0.869569</td>\n      <td>0.001434</td>\n      <td>llama_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da772338248b91727fa_train</th>\n      <td>0.941164</td>\n      <td>-0.994278</td>\n      <td>[[6597, 1381], [220, 2449]]</td>\n      <td>0.639426</td>\n      <td>0.917572</td>\n      <td>0.753654</td>\n      <td>0.849629</td>\n      <td>0.030723</td>\n      <td>palm_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e92716642bed23d09fb55bad_train</th>\n      <td>0.983951</td>\n      <td>-0.136667</td>\n      <td>[[7794, 603], [84, 2716]]</td>\n      <td>0.818319</td>\n      <td>0.970000</td>\n      <td>0.887727</td>\n      <td>0.938644</td>\n      <td>0.007500</td>\n      <td>chatgpt_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc074172ca5a88577c0d5db7_train</th>\n      <td>0.961763</td>\n      <td>-0.928909</td>\n      <td>[[1421, 259], [22, 538]]</td>\n      <td>0.675031</td>\n      <td>0.960714</td>\n      <td>0.792926</td>\n      <td>0.874554</td>\n      <td>0.025000</td>\n      <td>claude_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>357d2f75d787f00787f2bfb31c367978d56fe2843e11ae420e2a3ccc538ad93e_train</th>\n      <td>0.946071</td>\n      <td>-0.967330</td>\n      <td>[[7289, 1111], [351, 2449]]</td>\n      <td>0.687921</td>\n      <td>0.874643</td>\n      <td>0.770126</td>\n      <td>0.869464</td>\n      <td>0.001429</td>\n      <td>llama_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>277d294ec1bf7b980608af53a29c176de2de7c1ffd062c77f36eabc843565065_train</th>\n      <td>0.931743</td>\n      <td>-0.995067</td>\n      <td>[[6563, 1837], [206, 2594]]</td>\n      <td>0.585421</td>\n      <td>0.926429</td>\n      <td>0.717466</td>\n      <td>0.817589</td>\n      <td>0.030357</td>\n      <td>palm_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>a617f5d6441618fcb86810cddd0538c3b18dd27901b0be621495d69be376d7c4_train</th>\n      <td>0.983967</td>\n      <td>-0.136667</td>\n      <td>[[7798, 602], [83, 2717]]</td>\n      <td>0.818620</td>\n      <td>0.970357</td>\n      <td>0.888054</td>\n      <td>0.938839</td>\n      <td>0.007857</td>\n      <td>chatgpt_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train using the uncleaned domains and training structures\n",
    "# evaluate\n",
    "train_df_claude_nc, test_df_claude_nc, adjusted_df_claude_cleaned, sample_ids_claude_nc = \\\n",
    "    TrainingDataHandler.split_training_data_frame_and_adjust_transfer_test_df(df_claude_nc, df_claude_cleaned)\n",
    "\n",
    "args = train_roberta.generate_args_for_training_roberta(\n",
    "    train_df = train_df_claude_nc, test_df = test_df_claude_nc, transfer_df=[adjusted_df_claude_cleaned, df_llama_cleaned, df_palm_cleaned, df_chatgpt_cleaned, test_df_claude_nc, df_llama_nc, df_palm_nc, df_chatgpt_nc],\n",
    "    save_model_path=f\"{RESULT_DIR}claude_direct_prompt_all_domains_multi_llm_not_cleaned{_prompt_str}\"\n",
    ")\n",
    "\n",
    "results_nc_train = train_roberta.run(args)\n",
    "df_not_cleaned_train = modify_and_store_df(results_nc_train, \"claude\", \n",
    "                                       _dfs_used_for_testing = [\"claude_cleaned\", \"llama_cleaned\", \"palm_cleaned\", \"chatgpt_cleaned\", \n",
    "                                                                \"claude_nc\", \"llama_nc\", \"palm_nc\", \"chatgpt_nc\"])\n",
    "df_not_cleaned_train.to_csv(f\"{RESULT_DIR}/claude_trained_original_samples_results{_prompt_str}.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T12:36:00.379987100Z",
     "start_time": "2025-09-11T12:36:00.312855600Z"
    }
   },
   "id": "e0b3719d9eea152d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Llama"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee7c5da9fbfd2de9"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4828, 'grad_norm': 5.453637599945068, 'learning_rate': 8.349867724867724e-07, 'epoch': 0.49603174603174605}\n",
      "{'loss': 0.2526, 'grad_norm': 3.4856503009796143, 'learning_rate': 6.69642857142857e-07, 'epoch': 0.9920634920634921}\n",
      "{'eval_loss': 0.2544172704219818, 'eval_accuracy': 0.9944196428571429, 'eval_f1': 0.9944196428571429, 'eval_precision': 0.9944196428571429, 'eval_recall': 0.9944196428571429, 'eval_runtime': 8.5938, 'eval_samples_per_second': 104.261, 'eval_steps_per_second': 13.033, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1495, 'grad_norm': 1.2772891521453857, 'learning_rate': 5.042989417989418e-07, 'epoch': 1.4880952380952381}\n",
      "{'loss': 0.1469, 'grad_norm': 0.2134893536567688, 'learning_rate': 3.3895502645502644e-07, 'epoch': 1.9841269841269842}\n",
      "{'eval_loss': 0.051856767386198044, 'eval_accuracy': 0.9866071428571429, 'eval_f1': 0.9866071428571429, 'eval_precision': 0.9866071428571429, 'eval_recall': 0.9866071428571429, 'eval_runtime': 8.5694, 'eval_samples_per_second': 104.558, 'eval_steps_per_second': 13.07, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1368, 'grad_norm': 0.27638953924179077, 'learning_rate': 1.736111111111111e-07, 'epoch': 2.4801587301587302}\n",
      "{'loss': 0.1219, 'grad_norm': 38.08544921875, 'learning_rate': 8.267195767195766e-09, 'epoch': 2.9761904761904763}\n",
      "{'eval_loss': 0.043106745928525925, 'eval_accuracy': 0.9899553571428571, 'eval_f1': 0.9899553571428571, 'eval_precision': 0.9899553571428571, 'eval_recall': 0.9899553571428571, 'eval_runtime': 8.5856, 'eval_samples_per_second': 104.361, 'eval_steps_per_second': 13.045, 'epoch': 3.0}\n",
      "{'train_runtime': 844.8612, 'train_samples_per_second': 28.634, 'train_steps_per_second': 3.579, 'train_loss': 0.21424322390051745, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.043106745928525925, 'eval_accuracy': 0.9899553571428571, 'eval_f1': 0.9899553571428571, 'eval_precision': 0.9899553571428571, 'eval_recall': 0.9899553571428571, 'eval_runtime': 8.5756, 'eval_samples_per_second': 104.482, 'eval_steps_per_second': 13.06, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                     roc_auc  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...  0.972394   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.927691   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.969946   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.988257   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...  0.972781   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...   0.92077   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.966671   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.988309   \n\n                                                   optimal_threshold  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...         -0.019174   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...         -0.998424   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...         -0.618815   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         -0.021371   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...         -0.019174   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...         -0.998367   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...         -0.047691   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         -0.017557   \n\n                                                                    conf_matrix  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...      [[1578, 102], [9, 549]]   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  [[6751, 1556], [283, 2491]]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...   [[7480, 498], [203, 2466]]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...    [[8119, 278], [34, 2766]]   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...     [[1578, 102], [10, 550]]   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  [[6915, 1485], [366, 2434]]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...   [[8041, 359], [362, 2438]]   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    [[8144, 256], [41, 2759]]   \n\n                                                   precision    recall  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...  0.843318  0.983871   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.615518  0.897981   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.831984  0.923942   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.908673  0.987857   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...  0.843558  0.982143   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  0.621077  0.869286   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.871648  0.870714   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.915091  0.985357   \n\n                                                          f1  accuracy  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...  0.908189  0.950402   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.730391   0.83404   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.875555   0.93416   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.946612  0.972135   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...  0.907591      0.95   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  0.724513  0.834732   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.871181  0.935625   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.948925  0.973482   \n\n                                                   tpr_at_fpr_0_01  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...        0.003584   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...        0.002163   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...             0.0   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...        0.002857   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...        0.003571   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...        0.003571   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...             0.0   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...        0.002857   \n\n                                                          df_used_for_testing  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...  adjusted_df_cleaned_llama   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...             claude_cleaned   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...               palm_cleaned   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...            chatgpt_cleaned   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...           test_df_nc_llama   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...           claude_uncleaned   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...             palm_uncleaned   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          chatgpt_uncleaned   \n\n                                                                                         domain_test  \\\n42ac23415e356a37eeac963961b928a57026c98d5a6e449...  [paraphrase_polish_human, paraphrase_polish_llm]   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  [paraphrase_polish_human, paraphrase_polish_llm]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  [paraphrase_polish_human, paraphrase_polish_llm]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  [paraphrase_polish_human, paraphrase_polish_llm]   \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...  [paraphrase_polish_human, paraphrase_polish_llm]   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  [paraphrase_polish_human, paraphrase_polish_llm]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  [paraphrase_polish_human, paraphrase_polish_llm]   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  [paraphrase_polish_human, paraphrase_polish_llm]   \n\n                                                    cleaned  \n42ac23415e356a37eeac963961b928a57026c98d5a6e449...     True  \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...     True  \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     True  \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     True  \n8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf6...    False  \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...    False  \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...    False  \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>df_used_for_testing</th>\n      <th>domain_test</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>42ac23415e356a37eeac963961b928a57026c98d5a6e449ffec9fb7707cd82e5_train</th>\n      <td>0.972394</td>\n      <td>-0.019174</td>\n      <td>[[1578, 102], [9, 549]]</td>\n      <td>0.843318</td>\n      <td>0.983871</td>\n      <td>0.908189</td>\n      <td>0.950402</td>\n      <td>0.003584</td>\n      <td>adjusted_df_cleaned_llama</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589ab8f5ff446db6e27e_train</th>\n      <td>0.927691</td>\n      <td>-0.998424</td>\n      <td>[[6751, 1556], [283, 2491]]</td>\n      <td>0.615518</td>\n      <td>0.897981</td>\n      <td>0.730391</td>\n      <td>0.83404</td>\n      <td>0.002163</td>\n      <td>claude_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da772338248b91727fa_train</th>\n      <td>0.969946</td>\n      <td>-0.618815</td>\n      <td>[[7480, 498], [203, 2466]]</td>\n      <td>0.831984</td>\n      <td>0.923942</td>\n      <td>0.875555</td>\n      <td>0.93416</td>\n      <td>0.0</td>\n      <td>palm_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e92716642bed23d09fb55bad_train</th>\n      <td>0.988257</td>\n      <td>-0.021371</td>\n      <td>[[8119, 278], [34, 2766]]</td>\n      <td>0.908673</td>\n      <td>0.987857</td>\n      <td>0.946612</td>\n      <td>0.972135</td>\n      <td>0.002857</td>\n      <td>chatgpt_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8c970afc0a2447163e3ace1b5f92ebeb818110163b88cf616ef13e11ba4dbd78_train</th>\n      <td>0.972781</td>\n      <td>-0.019174</td>\n      <td>[[1578, 102], [10, 550]]</td>\n      <td>0.843558</td>\n      <td>0.982143</td>\n      <td>0.907591</td>\n      <td>0.95</td>\n      <td>0.003571</td>\n      <td>test_df_nc_llama</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>d8648f9b583ae727f79759db0101edcdaaee2436e882146a1708a9b0a2dd7841_train</th>\n      <td>0.92077</td>\n      <td>-0.998367</td>\n      <td>[[6915, 1485], [366, 2434]]</td>\n      <td>0.621077</td>\n      <td>0.869286</td>\n      <td>0.724513</td>\n      <td>0.834732</td>\n      <td>0.003571</td>\n      <td>claude_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>277d294ec1bf7b980608af53a29c176de2de7c1ffd062c77f36eabc843565065_train</th>\n      <td>0.966671</td>\n      <td>-0.047691</td>\n      <td>[[8041, 359], [362, 2438]]</td>\n      <td>0.871648</td>\n      <td>0.870714</td>\n      <td>0.871181</td>\n      <td>0.935625</td>\n      <td>0.0</td>\n      <td>palm_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>a617f5d6441618fcb86810cddd0538c3b18dd27901b0be621495d69be376d7c4_train</th>\n      <td>0.988309</td>\n      <td>-0.017557</td>\n      <td>[[8144, 256], [41, 2759]]</td>\n      <td>0.915091</td>\n      <td>0.985357</td>\n      <td>0.948925</td>\n      <td>0.973482</td>\n      <td>0.002857</td>\n      <td>chatgpt_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_llm_temp = \"llama\"\n",
    "# train using the uncleaned domains and training structures\n",
    "# evaluate\n",
    "train_df, test_df, adjusted_df_cleaned, _ = \\\n",
    "    TrainingDataHandler.split_training_data_frame_and_adjust_transfer_test_df(uncleaned_df[_llm_temp], cleaned_df[_llm_temp])\n",
    "\n",
    "transfer_dfs = {f\"adjusted_df_cleaned_{_llm_temp}\": adjusted_df_cleaned}\n",
    "transfer_dfs.update({k+\"_cleaned\": df for k, df in cleaned_df.items() if k != _llm_temp})\n",
    "transfer_dfs.update({f\"test_df_nc_{_llm_temp}\": test_df})\n",
    "transfer_dfs.update({k+\"_uncleaned\": df for k, df in uncleaned_df.items() if k != _llm_temp})\n",
    "\n",
    "args = train_roberta.generate_args_for_training_roberta(\n",
    "    train_df = train_df, test_df = test_df, transfer_df=list(transfer_dfs.values()),\n",
    "    save_model_path=f\"{RESULT_DIR}{_llm_temp}_direct_prompt_all_domains_multi_llm_not_cleaned{_prompt_str}\"\n",
    ")\n",
    "results_nc_train = train_roberta.run(args)\n",
    "\n",
    "df_not_cleaned_train = modify_and_store_df(results_nc_train, _llm_temp, _transfer_df_dict=transfer_dfs)\n",
    "df_not_cleaned_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T13:14:46.744463Z",
     "start_time": "2025-09-11T12:37:04.599693Z"
    }
   },
   "id": "ece23b686b471f55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Palm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "288d3774361b0eb6"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4867, 'grad_norm': 7.516754627227783, 'learning_rate': 8.349867724867724e-07, 'epoch': 0.49603174603174605}\n",
      "{'loss': 0.2812, 'grad_norm': 27.3880558013916, 'learning_rate': 6.69642857142857e-07, 'epoch': 0.9920634920634921}\n",
      "{'eval_loss': 0.6746987104415894, 'eval_accuracy': 0.8002232142857143, 'eval_f1': 0.8002232142857143, 'eval_precision': 0.8002232142857143, 'eval_recall': 0.8002232142857143, 'eval_runtime': 8.462, 'eval_samples_per_second': 105.885, 'eval_steps_per_second': 13.236, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.207, 'grad_norm': 37.83607864379883, 'learning_rate': 5.042989417989418e-07, 'epoch': 1.4880952380952381}\n",
      "{'loss': 0.1726, 'grad_norm': 0.4003298580646515, 'learning_rate': 3.3895502645502644e-07, 'epoch': 1.9841269841269842}\n",
      "{'eval_loss': 0.295428991317749, 'eval_accuracy': 0.9185267857142857, 'eval_f1': 0.9185267857142857, 'eval_precision': 0.9185267857142857, 'eval_recall': 0.9185267857142857, 'eval_runtime': 8.4316, 'eval_samples_per_second': 106.267, 'eval_steps_per_second': 13.283, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1616, 'grad_norm': 0.4697631597518921, 'learning_rate': 1.736111111111111e-07, 'epoch': 2.4801587301587302}\n",
      "{'loss': 0.1562, 'grad_norm': 0.16491959989070892, 'learning_rate': 8.267195767195766e-09, 'epoch': 2.9761904761904763}\n",
      "{'eval_loss': 0.33069083094596863, 'eval_accuracy': 0.9174107142857143, 'eval_f1': 0.9174107142857143, 'eval_precision': 0.9174107142857143, 'eval_recall': 0.9174107142857143, 'eval_runtime': 8.4243, 'eval_samples_per_second': 106.36, 'eval_steps_per_second': 13.295, 'epoch': 3.0}\n",
      "{'train_runtime': 842.9332, 'train_samples_per_second': 28.7, 'train_steps_per_second': 3.587, 'train_loss': 0.24400247057909688, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33069083094596863, 'eval_accuracy': 0.9174107142857143, 'eval_f1': 0.9174107142857143, 'eval_precision': 0.9174107142857143, 'eval_recall': 0.9174107142857143, 'eval_runtime': 8.4203, 'eval_samples_per_second': 106.41, 'eval_steps_per_second': 13.301, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                     roc_auc  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...  0.978056   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.929727   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.967572   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...   0.99231   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...  0.975207   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  0.928356   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...   0.96767   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.992314   \n\n                                                   optimal_threshold  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...         -0.186382   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...         -0.993838   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...         -0.812387   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         -0.011005   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...         -0.184362   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...         -0.993868   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...         -0.755112   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         -0.011005   \n\n                                                                    conf_matrix  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...     [[1482, 103], [36, 497]]   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  [[6774, 1533], [312, 2462]]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  [[7345, 1051], [112, 2678]]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...    [[8061, 336], [56, 2744]]   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...     [[1576, 104], [46, 514]]   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  [[6840, 1560], [307, 2493]]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  [[7385, 1015], [125, 2675]]   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    [[8063, 337], [57, 2743]]   \n\n                                                   precision    recall  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...  0.828333  0.932458   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...   0.61627  0.887527   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.718155  0.959857   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.890909      0.98   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...  0.831715  0.917857   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...    0.6151  0.890357   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.724932  0.955357   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.890584  0.979643   \n\n                                                          f1  accuracy  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...  0.877317  0.934372   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.727434  0.833499   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.821598  0.896031   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.933333  0.964991   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...  0.872666  0.933036   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  0.727565  0.833304   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.824345  0.898214   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.932993  0.964821   \n\n                                                   tpr_at_fpr_0_01  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...        0.028143   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...        0.011175   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...         0.00681   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...        0.003571   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...        0.026786   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...        0.006786   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...        0.006429   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...        0.002857   \n\n                                                         df_used_for_testing  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...  adjusted_df_cleaned_palm   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...            claude_cleaned   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...             llama_cleaned   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...           chatgpt_cleaned   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...           test_df_nc_palm   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...          claude_uncleaned   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...           llama_uncleaned   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         chatgpt_uncleaned   \n\n                                                                                         domain_test  \\\nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...  [paraphrase_polish_human, paraphrase_polish_llm]   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  [paraphrase_polish_human, paraphrase_polish_llm]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  [paraphrase_polish_human, paraphrase_polish_llm]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  [paraphrase_polish_human, paraphrase_polish_llm]   \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...  [paraphrase_polish_human, paraphrase_polish_llm]   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  [paraphrase_polish_human, paraphrase_polish_llm]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  [paraphrase_polish_human, paraphrase_polish_llm]   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  [paraphrase_polish_human, paraphrase_polish_llm]   \n\n                                                    cleaned  \nf70ba38644f688500f57994260d5b5f312fec7bf5bb66ff...     True  \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...     True  \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     True  \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     True  \nb099a90d99cf3f966c67518684a866bce99ac213e026a4d...    False  \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...    False  \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...    False  \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>df_used_for_testing</th>\n      <th>domain_test</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f70ba38644f688500f57994260d5b5f312fec7bf5bb66ffed666b2846faf2132_train</th>\n      <td>0.978056</td>\n      <td>-0.186382</td>\n      <td>[[1482, 103], [36, 497]]</td>\n      <td>0.828333</td>\n      <td>0.932458</td>\n      <td>0.877317</td>\n      <td>0.934372</td>\n      <td>0.028143</td>\n      <td>adjusted_df_cleaned_palm</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589ab8f5ff446db6e27e_train</th>\n      <td>0.929727</td>\n      <td>-0.993838</td>\n      <td>[[6774, 1533], [312, 2462]]</td>\n      <td>0.61627</td>\n      <td>0.887527</td>\n      <td>0.727434</td>\n      <td>0.833499</td>\n      <td>0.011175</td>\n      <td>claude_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536f7e5cedc7762c67b8_train</th>\n      <td>0.967572</td>\n      <td>-0.812387</td>\n      <td>[[7345, 1051], [112, 2678]]</td>\n      <td>0.718155</td>\n      <td>0.959857</td>\n      <td>0.821598</td>\n      <td>0.896031</td>\n      <td>0.00681</td>\n      <td>llama_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e92716642bed23d09fb55bad_train</th>\n      <td>0.99231</td>\n      <td>-0.011005</td>\n      <td>[[8061, 336], [56, 2744]]</td>\n      <td>0.890909</td>\n      <td>0.98</td>\n      <td>0.933333</td>\n      <td>0.964991</td>\n      <td>0.003571</td>\n      <td>chatgpt_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>b099a90d99cf3f966c67518684a866bce99ac213e026a4d31fa5bee5ff6d1235_train</th>\n      <td>0.975207</td>\n      <td>-0.184362</td>\n      <td>[[1576, 104], [46, 514]]</td>\n      <td>0.831715</td>\n      <td>0.917857</td>\n      <td>0.872666</td>\n      <td>0.933036</td>\n      <td>0.026786</td>\n      <td>test_df_nc_palm</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>d8648f9b583ae727f79759db0101edcdaaee2436e882146a1708a9b0a2dd7841_train</th>\n      <td>0.928356</td>\n      <td>-0.993868</td>\n      <td>[[6840, 1560], [307, 2493]]</td>\n      <td>0.6151</td>\n      <td>0.890357</td>\n      <td>0.727565</td>\n      <td>0.833304</td>\n      <td>0.006786</td>\n      <td>claude_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>357d2f75d787f00787f2bfb31c367978d56fe2843e11ae420e2a3ccc538ad93e_train</th>\n      <td>0.96767</td>\n      <td>-0.755112</td>\n      <td>[[7385, 1015], [125, 2675]]</td>\n      <td>0.724932</td>\n      <td>0.955357</td>\n      <td>0.824345</td>\n      <td>0.898214</td>\n      <td>0.006429</td>\n      <td>llama_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>a617f5d6441618fcb86810cddd0538c3b18dd27901b0be621495d69be376d7c4_train</th>\n      <td>0.992314</td>\n      <td>-0.011005</td>\n      <td>[[8063, 337], [57, 2743]]</td>\n      <td>0.890584</td>\n      <td>0.979643</td>\n      <td>0.932993</td>\n      <td>0.964821</td>\n      <td>0.002857</td>\n      <td>chatgpt_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_llm_temp = \"palm\"\n",
    "# train using the uncleaned domains and training structures\n",
    "# evaluate\n",
    "train_df, test_df, adjusted_df_cleaned, _ = \\\n",
    "    TrainingDataHandler.split_training_data_frame_and_adjust_transfer_test_df(uncleaned_df[_llm_temp], cleaned_df[_llm_temp])\n",
    "\n",
    "transfer_dfs = {f\"adjusted_df_cleaned_{_llm_temp}\": adjusted_df_cleaned}\n",
    "transfer_dfs.update({k+\"_cleaned\": df for k, df in cleaned_df.items() if k != _llm_temp})\n",
    "transfer_dfs.update({f\"test_df_nc_{_llm_temp}\": test_df})\n",
    "transfer_dfs.update({k+\"_uncleaned\": df for k, df in uncleaned_df.items() if k != _llm_temp})\n",
    "\n",
    "args = train_roberta.generate_args_for_training_roberta(\n",
    "    train_df = train_df, test_df = test_df, transfer_df=list(transfer_dfs.values()),\n",
    "    save_model_path=f\"{RESULT_DIR}{_llm_temp}_direct_prompt_all_domains_multi_llm_not_cleaned{_prompt_str}\"\n",
    ")\n",
    "results_nc_train = train_roberta.run(args)\n",
    "\n",
    "df_not_cleaned_train = modify_and_store_df(results_nc_train, _llm_temp, _transfer_df_dict=transfer_dfs)\n",
    "df_not_cleaned_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T13:52:45.910586100Z",
     "start_time": "2025-09-11T13:14:46.755443400Z"
    }
   },
   "id": "463944af79a797df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ChatGPT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7864a726aa8be490"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4192, 'grad_norm': 2.6958460807800293, 'learning_rate': 8.349867724867724e-07, 'epoch': 0.49603174603174605}\n",
      "{'loss': 0.0784, 'grad_norm': 7.502600193023682, 'learning_rate': 6.69642857142857e-07, 'epoch': 0.9920634920634921}\n",
      "{'eval_loss': 0.12219888716936111, 'eval_accuracy': 0.9654017857142857, 'eval_f1': 0.9654017857142857, 'eval_precision': 0.9654017857142857, 'eval_recall': 0.9654017857142857, 'eval_runtime': 8.6474, 'eval_samples_per_second': 103.615, 'eval_steps_per_second': 12.952, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0679, 'grad_norm': 0.44616591930389404, 'learning_rate': 5.042989417989418e-07, 'epoch': 1.4880952380952381}\n",
      "{'loss': 0.0475, 'grad_norm': 0.03494182229042053, 'learning_rate': 3.3895502645502644e-07, 'epoch': 1.9841269841269842}\n",
      "{'eval_loss': 0.04229801893234253, 'eval_accuracy': 0.9910714285714286, 'eval_f1': 0.9910714285714286, 'eval_precision': 0.9910714285714286, 'eval_recall': 0.9910714285714286, 'eval_runtime': 8.6133, 'eval_samples_per_second': 104.025, 'eval_steps_per_second': 13.003, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0464, 'grad_norm': 0.020010611042380333, 'learning_rate': 1.736111111111111e-07, 'epoch': 2.4801587301587302}\n",
      "{'loss': 0.0482, 'grad_norm': 0.12514695525169373, 'learning_rate': 8.267195767195766e-09, 'epoch': 2.9761904761904763}\n",
      "{'eval_loss': 0.03483090177178383, 'eval_accuracy': 0.9921875, 'eval_f1': 0.9921875, 'eval_precision': 0.9921875, 'eval_recall': 0.9921875, 'eval_runtime': 8.6156, 'eval_samples_per_second': 103.997, 'eval_steps_per_second': 13.0, 'epoch': 3.0}\n",
      "{'train_runtime': 847.9006, 'train_samples_per_second': 28.532, 'train_steps_per_second': 3.566, 'train_loss': 0.11750469246396313, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03483090177178383, 'eval_accuracy': 0.9921875, 'eval_f1': 0.9921875, 'eval_precision': 0.9921875, 'eval_recall': 0.9921875, 'eval_runtime': 8.6068, 'eval_samples_per_second': 104.104, 'eval_steps_per_second': 13.013, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                     roc_auc  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...  0.995107   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.932084   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.965621   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.953195   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...   0.99512   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  0.911325   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.963928   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.937213   \n\n                                                   optimal_threshold  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...         -0.002935   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...         -0.999554   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...          -0.99947   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...         -0.999534   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...         -0.006331   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...          -0.99957   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...          -0.99947   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...         -0.999541   \n\n                                                                    conf_matrix  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...       [[1652, 26], [9, 551]]   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  [[7008, 1299], [321, 2453]]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...   [[7557, 839], [195, 2595]]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...   [[7208, 770], [296, 2373]]   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...       [[1651, 29], [8, 552]]   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  [[7048, 1352], [445, 2355]]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...   [[7570, 830], [218, 2582]]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  [[7285, 1115], [331, 2469]]   \n\n                                                   precision    recall  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...  0.954939  0.983929   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.653785  0.884283   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.755679  0.930108   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.755011  0.889097   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...  0.950086  0.985714   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  0.635285  0.841071   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.756741  0.922143   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.688895  0.881786   \n\n                                                          f1  accuracy  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...  0.969217  0.984361   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  0.751762  0.853804   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.833869  0.907563   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.816586  0.899878   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...  0.967572  0.983482   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  0.723836  0.839554   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.831294  0.906429   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.773496  0.870893   \n\n                                                   tpr_at_fpr_0_01  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...           0.025   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...        0.001442   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...        0.000717   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...        0.002623   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...           0.025   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...        0.000357   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...        0.000357   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...        0.002857   \n\n                                                            df_used_for_testing  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...  adjusted_df_cleaned_chatgpt   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...               claude_cleaned   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...                llama_cleaned   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...                 palm_cleaned   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...           test_df_nc_chatgpt   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...             claude_uncleaned   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...              llama_uncleaned   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...               palm_uncleaned   \n\n                                                                                         domain_test  \\\ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...  [paraphrase_polish_human, paraphrase_polish_llm]   \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...  [paraphrase_polish_human, paraphrase_polish_llm]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  [paraphrase_polish_human, paraphrase_polish_llm]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  [paraphrase_polish_human, paraphrase_polish_llm]   \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...  [paraphrase_polish_human, paraphrase_polish_llm]   \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...  [paraphrase_polish_human, paraphrase_polish_llm]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  [paraphrase_polish_human, paraphrase_polish_llm]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  [paraphrase_polish_human, paraphrase_polish_llm]   \n\n                                                    cleaned  \ncc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492...     True  \n4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589...     True  \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     True  \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     True  \nc01b13da64ea707c8f2c88ceed8230175060190724fc309...    False  \nd8648f9b583ae727f79759db0101edcdaaee2436e882146...    False  \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...    False  \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>df_used_for_testing</th>\n      <th>domain_test</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cc23eb4ef7575015f3f8ad6380b2e1249f4b18fba614492a5cc21edcf01b7689_train</th>\n      <td>0.995107</td>\n      <td>-0.002935</td>\n      <td>[[1652, 26], [9, 551]]</td>\n      <td>0.954939</td>\n      <td>0.983929</td>\n      <td>0.969217</td>\n      <td>0.984361</td>\n      <td>0.025</td>\n      <td>adjusted_df_cleaned_chatgpt</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4387ef05e11901e66121939b9e0f6fbe0eb04fbd1f22589ab8f5ff446db6e27e_train</th>\n      <td>0.932084</td>\n      <td>-0.999554</td>\n      <td>[[7008, 1299], [321, 2453]]</td>\n      <td>0.653785</td>\n      <td>0.884283</td>\n      <td>0.751762</td>\n      <td>0.853804</td>\n      <td>0.001442</td>\n      <td>claude_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536f7e5cedc7762c67b8_train</th>\n      <td>0.965621</td>\n      <td>-0.99947</td>\n      <td>[[7557, 839], [195, 2595]]</td>\n      <td>0.755679</td>\n      <td>0.930108</td>\n      <td>0.833869</td>\n      <td>0.907563</td>\n      <td>0.000717</td>\n      <td>llama_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da772338248b91727fa_train</th>\n      <td>0.953195</td>\n      <td>-0.999534</td>\n      <td>[[7208, 770], [296, 2373]]</td>\n      <td>0.755011</td>\n      <td>0.889097</td>\n      <td>0.816586</td>\n      <td>0.899878</td>\n      <td>0.002623</td>\n      <td>palm_cleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>c01b13da64ea707c8f2c88ceed8230175060190724fc3094021851ea6e4fa45a_train</th>\n      <td>0.99512</td>\n      <td>-0.006331</td>\n      <td>[[1651, 29], [8, 552]]</td>\n      <td>0.950086</td>\n      <td>0.985714</td>\n      <td>0.967572</td>\n      <td>0.983482</td>\n      <td>0.025</td>\n      <td>test_df_nc_chatgpt</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>d8648f9b583ae727f79759db0101edcdaaee2436e882146a1708a9b0a2dd7841_train</th>\n      <td>0.911325</td>\n      <td>-0.99957</td>\n      <td>[[7048, 1352], [445, 2355]]</td>\n      <td>0.635285</td>\n      <td>0.841071</td>\n      <td>0.723836</td>\n      <td>0.839554</td>\n      <td>0.000357</td>\n      <td>claude_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>357d2f75d787f00787f2bfb31c367978d56fe2843e11ae420e2a3ccc538ad93e_train</th>\n      <td>0.963928</td>\n      <td>-0.99947</td>\n      <td>[[7570, 830], [218, 2582]]</td>\n      <td>0.756741</td>\n      <td>0.922143</td>\n      <td>0.831294</td>\n      <td>0.906429</td>\n      <td>0.000357</td>\n      <td>llama_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>277d294ec1bf7b980608af53a29c176de2de7c1ffd062c77f36eabc843565065_train</th>\n      <td>0.937213</td>\n      <td>-0.999541</td>\n      <td>[[7285, 1115], [331, 2469]]</td>\n      <td>0.688895</td>\n      <td>0.881786</td>\n      <td>0.773496</td>\n      <td>0.870893</td>\n      <td>0.002857</td>\n      <td>palm_uncleaned</td>\n      <td>[paraphrase_polish_human, paraphrase_polish_llm]</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_llm_temp = \"chatgpt\"\n",
    "# train using the uncleaned domains and training structures\n",
    "# evaluate\n",
    "train_df, test_df, adjusted_df_cleaned, _ = \\\n",
    "    TrainingDataHandler.split_training_data_frame_and_adjust_transfer_test_df(uncleaned_df[_llm_temp], cleaned_df[_llm_temp])\n",
    "\n",
    "transfer_dfs = {f\"adjusted_df_cleaned_{_llm_temp}\": adjusted_df_cleaned}\n",
    "transfer_dfs.update({k+\"_cleaned\": df for k, df in cleaned_df.items() if k != _llm_temp})\n",
    "transfer_dfs.update({f\"test_df_nc_{_llm_temp}\": test_df})\n",
    "transfer_dfs.update({k+\"_uncleaned\": df for k, df in uncleaned_df.items() if k != _llm_temp})\n",
    "\n",
    "args = train_roberta.generate_args_for_training_roberta(\n",
    "    train_df = train_df, test_df = test_df, transfer_df=list(transfer_dfs.values()),\n",
    "    save_model_path=f\"{RESULT_DIR}{_llm_temp}_direct_prompt_all_domains_multi_llm_not_cleaned{_prompt_str}\"\n",
    ")\n",
    "results_nc_train = train_roberta.run(args)\n",
    "\n",
    "df_not_cleaned_train = modify_and_store_df(results_nc_train, _llm_temp, _transfer_df_dict=transfer_dfs)\n",
    "df_not_cleaned_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T14:30:32.582939500Z",
     "start_time": "2025-09-11T13:52:45.916900400Z"
    }
   },
   "id": "a4b96d32fe222717"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Result Evaluation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bac103090517b9f4"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'/mnt/hdd-baracuda/pdingfelder/mt_philipp_dingfelder_generated_text_detection/src/../results/T01/claude_trained_original_samples_results_paraphrase_polish_human-paraphrase_polish_llm.csv'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{RESULT_DIR}/claude_trained_original_samples_results{_prompt_str}.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T15:22:31.017035700Z",
     "start_time": "2025-09-11T15:22:30.990118800Z"
    }
   },
   "id": "20c48003ef1141bc"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                     roc_auc  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.975549   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.975582   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.983967   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.983951   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.961399   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.956643   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.961763   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.960867   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.930352   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.945368   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.931743   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.941164   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.944598   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.948450   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.946071   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.946975   \n\n                                                    optimal_threshold  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          -0.176101   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...          -0.176101   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          -0.136667   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...          -0.136667   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...          -0.966674   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...          -0.754963   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...          -0.928909   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...          -0.940477   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...          -0.994870   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...          -0.994146   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...          -0.995067   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...          -0.994278   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...          -0.984199   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...          -0.974335   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...          -0.967330   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...          -0.967297   \n\n                                                                    conf_matrix  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    [[7834, 566], [66, 2734]]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...    [[7829, 568], [64, 2736]]   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    [[7798, 602], [83, 2717]]   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...    [[7794, 603], [84, 2716]]   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...     [[1465, 215], [32, 528]]   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     [[1452, 207], [29, 523]]   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...     [[1421, 259], [22, 538]]   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     [[1406, 253], [20, 532]]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  [[6655, 1745], [183, 2617]]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  [[6601, 1377], [167, 2502]]   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  [[6563, 1837], [206, 2594]]   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  [[6597, 1381], [220, 2449]]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  [[7108, 1292], [271, 2529]]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  [[7260, 1136], [288, 2502]]   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  [[7289, 1111], [351, 2449]]   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  [[7281, 1115], [344, 2446]]   \n\n                                                    precision    recall  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...   0.828485  0.976429   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...   0.828087  0.977143   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...   0.818620  0.970357   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...   0.818319  0.970000   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...   0.710633  0.942857   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...   0.716438  0.947464   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...   0.675031  0.960714   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...   0.677707  0.963768   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...   0.599954  0.934643   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...   0.645012  0.937430   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...   0.585421  0.926429   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...   0.639426  0.917572   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...   0.661869  0.903214   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...   0.687741  0.896774   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...   0.687921  0.874643   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...   0.686886  0.876703   \n\n                                                          f1  accuracy  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.896393  0.943571   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.896461  0.943556   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  0.888054  0.938839   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  0.887727  0.938644   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.810437  0.889732   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.815913  0.893261   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  0.792926  0.874554   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  0.795812  0.876526   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.730801  0.827857   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.764203  0.854983   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  0.717466  0.817589   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  0.753654  0.849629   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.763933  0.860446   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.778469  0.872698   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  0.770126  0.869464   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  0.770272  0.869569   \n\n                                                    tpr_at_fpr_0_01  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         0.003214   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         0.003214   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         0.007857   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         0.007500   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...         0.025000   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...         0.001812   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...         0.025000   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...         0.021739   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...         0.000357   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...         0.001124   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...         0.030357   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...         0.030723   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...         0.000714   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...         0.000717   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...         0.001429   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...         0.001434   \n\n                                                   df_used_for_testing  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          chatgpt_nc   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     chatgpt_cleaned   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...          chatgpt_nc   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     chatgpt_cleaned   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...           claude_nc   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...      claude_cleaned   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...           claude_nc   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...      claude_cleaned   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...             palm_nc   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...        palm_cleaned   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...             palm_nc   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...        palm_cleaned   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...            llama_nc   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...       llama_cleaned   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...            llama_nc   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...       llama_cleaned   \n\n                                                                                          domain_test  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  ['paraphrase_polish_human', 'paraphrase_polish...   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  ['paraphrase_polish_human', 'paraphrase_polish...   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  ['paraphrase_polish_human', 'paraphrase_polish...   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  ['paraphrase_polish_human', 'paraphrase_polish...   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  ['paraphrase_polish_human', 'paraphrase_polish...   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  ['paraphrase_polish_human', 'paraphrase_polish...   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  ['paraphrase_polish_human', 'paraphrase_polish...   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  ['paraphrase_polish_human', 'paraphrase_polish...   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  ['paraphrase_polish_human', 'paraphrase_polish...   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  ['paraphrase_polish_human', 'paraphrase_polish...   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  ['paraphrase_polish_human', 'paraphrase_polish...   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  ['paraphrase_polish_human', 'paraphrase_polish...   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  ['paraphrase_polish_human', 'paraphrase_polish...   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  ['paraphrase_polish_human', 'paraphrase_polish...   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  ['paraphrase_polish_human', 'paraphrase_polish...   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  ['paraphrase_polish_human', 'paraphrase_polish...   \n\n                                                    cleaned  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    False   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     True   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    False   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...     True   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...    False   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     True   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...    False   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...     True   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...    False   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     True   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...    False   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     True   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...    False   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     True   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...    False   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     True   \n\n                                                                   llm_train  \\\na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...    Claude-instant_cleaned   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...    Claude-instant_cleaned   \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...  Claude-instant_uncleaned   \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...  Claude-instant_uncleaned   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...    Claude-instant_cleaned   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...    Claude-instant_cleaned   \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  Claude-instant_uncleaned   \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  Claude-instant_uncleaned   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...    Claude-instant_cleaned   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...    Claude-instant_cleaned   \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...  Claude-instant_uncleaned   \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...  Claude-instant_uncleaned   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...    Claude-instant_cleaned   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...    Claude-instant_cleaned   \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...  Claude-instant_uncleaned   \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...  Claude-instant_uncleaned   \n\n                                                          llm_test  \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         ChatGPT  \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         ChatGPT  \na617f5d6441618fcb86810cddd0538c3b18dd27901b0be6...         ChatGPT  \n9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e927166...         ChatGPT  \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  Claude-instant  \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  Claude-instant  \n7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc07417...  Claude-instant  \nfd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50b...  Claude-instant  \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...     Google-PaLM  \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     Google-PaLM  \n277d294ec1bf7b980608af53a29c176de2de7c1ffd062c7...     Google-PaLM  \n2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da...     Google-PaLM  \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...     Llama-2-70b  \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     Llama-2-70b  \n357d2f75d787f00787f2bfb31c367978d56fe2843e11ae4...     Llama-2-70b  \n15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536...     Llama-2-70b  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc</th>\n      <th>optimal_threshold</th>\n      <th>conf_matrix</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n      <th>df_used_for_testing</th>\n      <th>domain_test</th>\n      <th>cleaned</th>\n      <th>llm_train</th>\n      <th>llm_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a617f5d6441618fcb86810cddd0538c3b18dd27901b0be621495d69be376d7c4_train</th>\n      <td>0.975549</td>\n      <td>-0.176101</td>\n      <td>[[7834, 566], [66, 2734]]</td>\n      <td>0.828485</td>\n      <td>0.976429</td>\n      <td>0.896393</td>\n      <td>0.943571</td>\n      <td>0.003214</td>\n      <td>chatgpt_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_cleaned</td>\n      <td>ChatGPT</td>\n    </tr>\n    <tr>\n      <th>9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e92716642bed23d09fb55bad_train</th>\n      <td>0.975582</td>\n      <td>-0.176101</td>\n      <td>[[7829, 568], [64, 2736]]</td>\n      <td>0.828087</td>\n      <td>0.977143</td>\n      <td>0.896461</td>\n      <td>0.943556</td>\n      <td>0.003214</td>\n      <td>chatgpt_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_cleaned</td>\n      <td>ChatGPT</td>\n    </tr>\n    <tr>\n      <th>a617f5d6441618fcb86810cddd0538c3b18dd27901b0be621495d69be376d7c4_train</th>\n      <td>0.983967</td>\n      <td>-0.136667</td>\n      <td>[[7798, 602], [83, 2717]]</td>\n      <td>0.818620</td>\n      <td>0.970357</td>\n      <td>0.888054</td>\n      <td>0.938839</td>\n      <td>0.007857</td>\n      <td>chatgpt_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>ChatGPT</td>\n    </tr>\n    <tr>\n      <th>9d000c4d3a86c02e1ec8e6362801ee731c46b2e4e92716642bed23d09fb55bad_train</th>\n      <td>0.983951</td>\n      <td>-0.136667</td>\n      <td>[[7794, 603], [84, 2716]]</td>\n      <td>0.818319</td>\n      <td>0.970000</td>\n      <td>0.887727</td>\n      <td>0.938644</td>\n      <td>0.007500</td>\n      <td>chatgpt_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>ChatGPT</td>\n    </tr>\n    <tr>\n      <th>7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc074172ca5a88577c0d5db7_train</th>\n      <td>0.961399</td>\n      <td>-0.966674</td>\n      <td>[[1465, 215], [32, 528]]</td>\n      <td>0.710633</td>\n      <td>0.942857</td>\n      <td>0.810437</td>\n      <td>0.889732</td>\n      <td>0.025000</td>\n      <td>claude_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_cleaned</td>\n      <td>Claude-instant</td>\n    </tr>\n    <tr>\n      <th>fd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50ba7b748eacd56133c2_train</th>\n      <td>0.956643</td>\n      <td>-0.754963</td>\n      <td>[[1452, 207], [29, 523]]</td>\n      <td>0.716438</td>\n      <td>0.947464</td>\n      <td>0.815913</td>\n      <td>0.893261</td>\n      <td>0.001812</td>\n      <td>claude_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_cleaned</td>\n      <td>Claude-instant</td>\n    </tr>\n    <tr>\n      <th>7b0f4bc09e69e9439960e32e5c4443fe85a9da3fbc074172ca5a88577c0d5db7_train</th>\n      <td>0.961763</td>\n      <td>-0.928909</td>\n      <td>[[1421, 259], [22, 538]]</td>\n      <td>0.675031</td>\n      <td>0.960714</td>\n      <td>0.792926</td>\n      <td>0.874554</td>\n      <td>0.025000</td>\n      <td>claude_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>Claude-instant</td>\n    </tr>\n    <tr>\n      <th>fd7e0fb49d10b6e5054a4b0f7a4d40ec633e3d4ef73f50ba7b748eacd56133c2_train</th>\n      <td>0.960867</td>\n      <td>-0.940477</td>\n      <td>[[1406, 253], [20, 532]]</td>\n      <td>0.677707</td>\n      <td>0.963768</td>\n      <td>0.795812</td>\n      <td>0.876526</td>\n      <td>0.021739</td>\n      <td>claude_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>Claude-instant</td>\n    </tr>\n    <tr>\n      <th>277d294ec1bf7b980608af53a29c176de2de7c1ffd062c77f36eabc843565065_train</th>\n      <td>0.930352</td>\n      <td>-0.994870</td>\n      <td>[[6655, 1745], [183, 2617]]</td>\n      <td>0.599954</td>\n      <td>0.934643</td>\n      <td>0.730801</td>\n      <td>0.827857</td>\n      <td>0.000357</td>\n      <td>palm_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_cleaned</td>\n      <td>Google-PaLM</td>\n    </tr>\n    <tr>\n      <th>2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da772338248b91727fa_train</th>\n      <td>0.945368</td>\n      <td>-0.994146</td>\n      <td>[[6601, 1377], [167, 2502]]</td>\n      <td>0.645012</td>\n      <td>0.937430</td>\n      <td>0.764203</td>\n      <td>0.854983</td>\n      <td>0.001124</td>\n      <td>palm_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_cleaned</td>\n      <td>Google-PaLM</td>\n    </tr>\n    <tr>\n      <th>277d294ec1bf7b980608af53a29c176de2de7c1ffd062c77f36eabc843565065_train</th>\n      <td>0.931743</td>\n      <td>-0.995067</td>\n      <td>[[6563, 1837], [206, 2594]]</td>\n      <td>0.585421</td>\n      <td>0.926429</td>\n      <td>0.717466</td>\n      <td>0.817589</td>\n      <td>0.030357</td>\n      <td>palm_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>Google-PaLM</td>\n    </tr>\n    <tr>\n      <th>2e8af8cbf8341eaae174ec2875ff8ec8147b74084f1a1da772338248b91727fa_train</th>\n      <td>0.941164</td>\n      <td>-0.994278</td>\n      <td>[[6597, 1381], [220, 2449]]</td>\n      <td>0.639426</td>\n      <td>0.917572</td>\n      <td>0.753654</td>\n      <td>0.849629</td>\n      <td>0.030723</td>\n      <td>palm_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>Google-PaLM</td>\n    </tr>\n    <tr>\n      <th>357d2f75d787f00787f2bfb31c367978d56fe2843e11ae420e2a3ccc538ad93e_train</th>\n      <td>0.944598</td>\n      <td>-0.984199</td>\n      <td>[[7108, 1292], [271, 2529]]</td>\n      <td>0.661869</td>\n      <td>0.903214</td>\n      <td>0.763933</td>\n      <td>0.860446</td>\n      <td>0.000714</td>\n      <td>llama_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_cleaned</td>\n      <td>Llama-2-70b</td>\n    </tr>\n    <tr>\n      <th>15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536f7e5cedc7762c67b8_train</th>\n      <td>0.948450</td>\n      <td>-0.974335</td>\n      <td>[[7260, 1136], [288, 2502]]</td>\n      <td>0.687741</td>\n      <td>0.896774</td>\n      <td>0.778469</td>\n      <td>0.872698</td>\n      <td>0.000717</td>\n      <td>llama_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_cleaned</td>\n      <td>Llama-2-70b</td>\n    </tr>\n    <tr>\n      <th>357d2f75d787f00787f2bfb31c367978d56fe2843e11ae420e2a3ccc538ad93e_train</th>\n      <td>0.946071</td>\n      <td>-0.967330</td>\n      <td>[[7289, 1111], [351, 2449]]</td>\n      <td>0.687921</td>\n      <td>0.874643</td>\n      <td>0.770126</td>\n      <td>0.869464</td>\n      <td>0.001429</td>\n      <td>llama_nc</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>False</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>Llama-2-70b</td>\n    </tr>\n    <tr>\n      <th>15268a30d1c466d21c6e16ba7b5a4b76d01ad9c5eb5b536f7e5cedc7762c67b8_train</th>\n      <td>0.946975</td>\n      <td>-0.967297</td>\n      <td>[[7281, 1115], [344, 2446]]</td>\n      <td>0.686886</td>\n      <td>0.876703</td>\n      <td>0.770272</td>\n      <td>0.869569</td>\n      <td>0.001434</td>\n      <td>llama_cleaned</td>\n      <td>['paraphrase_polish_human', 'paraphrase_polish...</td>\n      <td>True</td>\n      <td>Claude-instant_uncleaned</td>\n      <td>Llama-2-70b</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_train_claude = pd.read_csv(f\"{RESULT_DIR}/claude_trained_cleaned_samples_results{_prompt_str}.csv\", index_col=0)\n",
    "df_cleaned_train_claude[\"llm_train\"] = \"Claude-instant_cleaned\"\n",
    "df_cleaned_train_claude[\"llm_test\"] = [\"Claude-instant\", \"Llama-2-70b\", \"Google-PaLM\", \"ChatGPT\", \"Claude-instant\", \"Llama-2-70b\", \"Google-PaLM\", \"ChatGPT\"]\n",
    "\n",
    "df_not_cleaned_claude = pd.read_csv(f\"{RESULT_DIR}/claude_trained_original_samples_results{_prompt_str}.csv\", index_col=0)\n",
    "df_not_cleaned_claude[\"llm_train\"] = \"Claude-instant_uncleaned\"\n",
    "df_not_cleaned_claude[\"llm_test\"] = [\"Claude-instant\", \"Llama-2-70b\", \"Google-PaLM\", \"ChatGPT\", \"Claude-instant\", \"Llama-2-70b\", \"Google-PaLM\", \"ChatGPT\"]\n",
    "\n",
    "df_claude_multi_domain_eval_multi_llm = pd.concat([df_cleaned_train_claude, df_not_cleaned_claude])\n",
    "df_claude_multi_domain_eval_multi_llm.sort_values(by=[\"llm_test\", \"llm_train\", \"cleaned\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T15:24:43.233356Z",
     "start_time": "2025-09-11T15:24:43.195989600Z"
    }
   },
   "id": "2210ceb71d1b72fe"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   roc_auc        f1  accuracy  \\\nllm_train                cleaned                                 \nClaude-instant_cleaned   False    0.950166  0.797043  0.877292   \n                         True     0.956467  0.813044  0.890412   \nClaude-instant_uncleaned False    0.953927  0.791882  0.875298   \n                         True     0.957364  0.803885  0.885947   \n\n                                  tpr_at_fpr_0_01  \nllm_train                cleaned                   \nClaude-instant_cleaned   False           0.001429  \n                         True            0.001685  \nClaude-instant_uncleaned False           0.013214  \n                         True            0.013219  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>roc_auc</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>tpr_at_fpr_0_01</th>\n    </tr>\n    <tr>\n      <th>llm_train</th>\n      <th>cleaned</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Claude-instant_cleaned</th>\n      <th>False</th>\n      <td>0.950166</td>\n      <td>0.797043</td>\n      <td>0.877292</td>\n      <td>0.001429</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>0.956467</td>\n      <td>0.813044</td>\n      <td>0.890412</td>\n      <td>0.001685</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Claude-instant_uncleaned</th>\n      <th>False</th>\n      <td>0.953927</td>\n      <td>0.791882</td>\n      <td>0.875298</td>\n      <td>0.013214</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>0.957364</td>\n      <td>0.803885</td>\n      <td>0.885947</td>\n      <td>0.013219</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_claude_multi_domain_eval_multi_llm[[\"roc_auc\", \"f1\", \"accuracy\", \"tpr_at_fpr_0_01\"]] = df_claude_multi_domain_eval_multi_llm[[\"roc_auc\", \"f1\", \"accuracy\", \"tpr_at_fpr_0_01\"]].astype(np.float32)\n",
    "df_claude_multi_domain_eval_multi_llm_wo_claude = df_claude_multi_domain_eval_multi_llm[df_claude_multi_domain_eval_multi_llm[\"llm_test\"]!=\"Claude-instant\"]\n",
    "df_claude_multi_domain_eval_multi_llm_wo_claude[[\"roc_auc\", \"f1\", \"accuracy\", \"tpr_at_fpr_0_01\", \"llm_train\", \"cleaned\"]].groupby(by=[\"llm_train\", \"cleaned\"]).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-11T15:26:09.639989300Z",
     "start_time": "2025-09-11T15:26:09.577857600Z"
    }
   },
   "id": "f2d66feb30690596"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
